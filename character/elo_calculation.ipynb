{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0b9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_from_disk\n",
    "from constants import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2badbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tested models (these will be loaded from data/)\n",
    "# NOTE: This list is for reference and plotting order only\n",
    "# Only models with both .pkl files and dataset directories will actually load\n",
    "tested_models = [\n",
    "    \"claude-haiku-4.5\",\n",
    "    \"deepseek-v3.2\",\n",
    "    \"gemini-3-flash-preview\",\n",
    "    \"gpt-5.1\",\n",
    "    \"grok-4.1-fast\",\n",
    "    \"kimi-k2-thinking\",\n",
    "    \"ministral-14b-2512\",\n",
    "    \"qwen3-vl-235b-a22b-thinking\",\n",
    "    \"trinity-mini\",\n",
    "]\n",
    "\n",
    "# Display names for plots (optional - can be customized)\n",
    "display_names = {\n",
    "    \"claude-haiku-4.5\": \"Claude Haiku 4.5\",\n",
    "    \"deepseek-v3.2\": \"DeepSeek V3.2\",\n",
    "    \"gemini-3-flash-preview\": \"Gemini 3 Flash\",\n",
    "    \"gpt-5.1\": \"GPT-5.1\",\n",
    "    \"grok-4.1-fast\": \"Grok 4.1 Fast\",\n",
    "    \"kimi-k2-thinking\": \"Kimi K2 Thinking\",\n",
    "    \"ministral-14b-2512\": \"Ministral 14B\",\n",
    "    \"qwen3-vl-235b-a22b-thinking\": \"Qwen3 VL 235B\",\n",
    "    \"trinity-mini\": \"Trinity Mini\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b52315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elo_ratings(preferences, model_name, normalize=False):\n",
    "    # get all unique traits from the comparisons\n",
    "    traits = set()\n",
    "    for x, y, _ in preferences[model_name]:\n",
    "        traits.add(x)\n",
    "        traits.add(y)\n",
    "\n",
    "    # initialize elo ratings (starting at 1000)\n",
    "    elo_ratings = {trait: 1000.0 for trait in traits}\n",
    "    \n",
    "    # TODO: update k-factor for elo calculation\n",
    "    # TODO: Adapt k to lower value in the trait:babble case\n",
    "    K = 32\n",
    "\n",
    "    # calculate elo ratings based on comparison results\n",
    "    for trait1, trait2, winner in preferences[model_name]:\n",
    "        # get current ratings\n",
    "        r1 = elo_ratings[trait1]\n",
    "        r2 = elo_ratings[trait2]\n",
    "        \n",
    "        # calculate expected scores\n",
    "        e1 = 1 / (1 + 10**((r2 - r1) / 400))\n",
    "        e2 = 1 / (1 + 10**((r1 - r2) / 400))\n",
    "        \n",
    "        # update ratings based on actual outcome\n",
    "        if winner == trait1:\n",
    "            elo_ratings[trait1] += K * (1 - e1)\n",
    "            elo_ratings[trait2] += K * (0 - e2)\n",
    "        elif winner == trait2:\n",
    "            elo_ratings[trait1] += K * (0 - e1)\n",
    "            elo_ratings[trait2] += K * (1 - e2)\n",
    "        else:\n",
    "            # no clear winner, judge rambled\n",
    "            pass\n",
    "\n",
    "    # normalize ratings to 0-1 range if requested\n",
    "    if normalize:\n",
    "        min_rating = min(elo_ratings.values())\n",
    "        max_rating = max(elo_ratings.values())\n",
    "        rating_range = max_rating - min_rating\n",
    "        if rating_range > 0:\n",
    "            for trait in elo_ratings:\n",
    "                elo_ratings[trait] = (elo_ratings[trait] - min_rating) / rating_range\n",
    "\n",
    "    # sort ratings in descending order\n",
    "    for k, v in elo_ratings.items():\n",
    "        elo_ratings[k] = round(v, 2)\n",
    "    sorted_ratings = sorted(elo_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536338ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded ministral-14b-2512: 10029 valid comparisons\n",
      "✓ Loaded trinity-mini: 9955 valid comparisons\n",
      "Warning: No dataset directory found for qwen-2.5-7b-instruct, skipping...\n",
      "✓ Loaded deepseek-v3.2: 10022 valid comparisons\n",
      "✓ Loaded gemini-3-flash-preview: 10243 valid comparisons\n",
      "✓ Loaded qwen3-vl-235b-a22b-thinking: 10255 valid comparisons\n",
      "✓ Loaded kimi-k2-thinking: 10034 valid comparisons\n",
      "✓ Loaded gemma-3-4b-it: 143 valid comparisons\n",
      "✓ Loaded gpt-5.1: 10246 valid comparisons\n",
      "✓ Loaded claude-haiku-4.5: 10247 valid comparisons\n",
      "✓ Loaded grok-4.1-fast: 10055 valid comparisons\n",
      "✓ Loaded llama-3.1-8b: 10112 valid comparisons\n",
      "\n",
      "============================================================\n",
      "Successfully loaded 11 models\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load preferences from pkl files (judge results)\n",
    "# Filter out empty responses (\"\") where judge failed to determine winner\n",
    "# Clean structure: pkl files and dataset directories are side-by-side in data/preferences/\n",
    "preferences_path = f\"{DATA_PATH}/preferences\"\n",
    "\n",
    "files = [f for f in os.listdir(preferences_path) if f.endswith(\".pkl\")]\n",
    "preferences = {}\n",
    "\n",
    "for file in files:\n",
    "    name = file.split(\".pkl\")[0]\n",
    "    pkl_path = f\"{preferences_path}/{file}\"\n",
    "    dataset_path = f\"{preferences_path}/{name}\"\n",
    "    \n",
    "    # Check if matching dataset directory exists\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        print(f\"Warning: No dataset directory found for {name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            data = load_from_disk(dataset_path)\n",
    "            winners = pickle.load(f)\n",
    "            # Filter out empty judge responses and cases where winner is not one of the traits\n",
    "            preferences[name] = [(t1, t2, winner) for t1, t2, winner in zip(data[\"trait_1\"], data[\"trait_2\"], winners) \n",
    "                                if winner and winner != \"\" and winner in [t1, t2]]\n",
    "        print(f\"✓ Loaded {name}: {len(preferences[name])} valid comparisons\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {name}: {e}\")\n",
    "\n",
    "# Get list of models from loaded data\n",
    "model_names = sorted(preferences.keys())\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Successfully loaded {len(model_names)} models\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Calculate Elo ratings for all models\n",
    "results = {}\n",
    "for model in model_names:\n",
    "    sorted_ratings = calculate_elo_ratings(preferences, model, False)\n",
    "    results[model] = sorted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6eabe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trait counts per model:\n",
      "============================================================\n",
      "claude-haiku-4.5                        : 144 traits\n",
      "deepseek-v3.2                           : 144 traits\n",
      "gemini-3-flash-preview                  : 144 traits\n",
      "gemma-3-4b-it                           : 122 traits\n",
      "gpt-5.1                                 : 144 traits\n",
      "grok-4.1-fast                           : 144 traits\n",
      "kimi-k2-thinking                        : 144 traits\n",
      "llama-3.1-8b                            : 144 traits\n",
      "ministral-14b-2512                      : 144 traits\n",
      "qwen3-vl-235b-a22b-thinking             : 144 traits\n",
      "trinity-mini                            : 144 traits\n",
      "\n",
      "Unique trait counts: [122, 144]\n",
      "\n",
      "Reference model (claude-haiku-4.5) has 144 traits\n",
      "\n",
      "Missing traits per model:\n",
      "\n",
      "gemma-3-4b-it:\n",
      "  Missing: ['academic', 'anxious', 'argumentative', 'assertive', 'blunt', 'colloquial', 'creative', 'credulous', 'excitable', 'factual', 'fierce', 'idealistic', 'irreverent', 'loving', 'methodical', 'nuanced', 'progressive', 'prosaic', 'sycophantic', 'technical', 'unapologetic', 'urgent']\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Investigate trait counts per model\n",
    "print(\"Trait counts per model:\")\n",
    "print(\"=\" * 60)\n",
    "for model in model_names:\n",
    "    num_traits = len(results[model])\n",
    "    print(f\"{model:40s}: {num_traits} traits\")\n",
    "\n",
    "# Find the models with different counts\n",
    "trait_counts = {model: len(results[model]) for model in model_names}\n",
    "unique_counts = set(trait_counts.values())\n",
    "print(f\"\\nUnique trait counts: {sorted(unique_counts)}\")\n",
    "\n",
    "# Show which traits are missing from models with fewer traits\n",
    "if len(unique_counts) > 1:\n",
    "    max_count = max(unique_counts)\n",
    "    models_with_max = [m for m, c in trait_counts.items() if c == max_count]\n",
    "    reference_model = models_with_max[0]\n",
    "    reference_traits = {trait for trait, _ in results[reference_model]}\n",
    "    \n",
    "    print(f\"\\nReference model ({reference_model}) has {max_count} traits\")\n",
    "    print(\"\\nMissing traits per model:\")\n",
    "    for model in model_names:\n",
    "        model_traits = {trait for trait, _ in results[model]}\n",
    "        missing = reference_traits - model_traits\n",
    "        extra = model_traits - reference_traits\n",
    "        if missing or extra:\n",
    "            print(f\"\\n{model}:\")\n",
    "            if missing:\n",
    "                print(f\"  Missing: {sorted(missing)}\")\n",
    "            if extra:\n",
    "                print(f\"  Extra: {sorted(extra)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c729f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Models (11):\n",
      "================================================================================\n",
      "claude-haiku-4.5                              - 10247 valid trait comparisons\n",
      "deepseek-v3.2                                 - 10022 valid trait comparisons\n",
      "gemini-3-flash-preview                        - 10243 valid trait comparisons\n",
      "gemma-3-4b-it                                 -   143 valid trait comparisons\n",
      "gpt-5.1                                       - 10246 valid trait comparisons\n",
      "grok-4.1-fast                                 - 10055 valid trait comparisons\n",
      "kimi-k2-thinking                              - 10034 valid trait comparisons\n",
      "llama-3.1-8b                                  - 10112 valid trait comparisons\n",
      "ministral-14b-2512                            - 10029 valid trait comparisons\n",
      "qwen3-vl-235b-a22b-thinking                   - 10255 valid trait comparisons\n",
      "trinity-mini                                  -  9955 valid trait comparisons\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show summary of loaded models and their valid comparisons\n",
    "print(f\"\\nLoaded Models ({len(model_names)}):\")\n",
    "print(\"=\" * 80)\n",
    "for model in model_names:\n",
    "    valid_comparisons = len(preferences[model])\n",
    "    print(f\"{model:45s} - {valid_comparisons:5d} valid trait comparisons\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef670878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claude-haiku-4.5</th>\n",
       "      <th>deepseek-v3.2</th>\n",
       "      <th>gemini-3-flash-preview</th>\n",
       "      <th>gemma-3-4b-it</th>\n",
       "      <th>gpt-5.1</th>\n",
       "      <th>grok-4.1-fast</th>\n",
       "      <th>kimi-k2-thinking</th>\n",
       "      <th>llama-3.1-8b</th>\n",
       "      <th>ministral-14b-2512</th>\n",
       "      <th>qwen3-vl-235b-a22b-thinking</th>\n",
       "      <th>trinity-mini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(concrete, 1420.41)</td>\n",
       "      <td>(literal, 1289.51)</td>\n",
       "      <td>(structured, 1556.26)</td>\n",
       "      <td>(declarative, 1071.51)</td>\n",
       "      <td>(structured, 1494.34)</td>\n",
       "      <td>(concrete, 1338.84)</td>\n",
       "      <td>(methodical, 1351.57)</td>\n",
       "      <td>(structured, 1334.62)</td>\n",
       "      <td>(disciplined, 1263.86)</td>\n",
       "      <td>(structured, 1335.22)</td>\n",
       "      <td>(precise, 1364.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(structured, 1408.72)</td>\n",
       "      <td>(structured, 1276.91)</td>\n",
       "      <td>(systematic, 1520.18)</td>\n",
       "      <td>(gentle, 1061.13)</td>\n",
       "      <td>(disciplined, 1445.78)</td>\n",
       "      <td>(pragmatic, 1291.51)</td>\n",
       "      <td>(structured, 1349.27)</td>\n",
       "      <td>(methodical, 1257.69)</td>\n",
       "      <td>(precise, 1262.73)</td>\n",
       "      <td>(precise, 1334.04)</td>\n",
       "      <td>(concrete, 1352.63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(grounding, 1378.89)</td>\n",
       "      <td>(systematic, 1265.3)</td>\n",
       "      <td>(scholarly, 1504.46)</td>\n",
       "      <td>(precise, 1059.77)</td>\n",
       "      <td>(methodical, 1436.45)</td>\n",
       "      <td>(rational, 1273.38)</td>\n",
       "      <td>(systematic, 1323.84)</td>\n",
       "      <td>(specialized, 1230.36)</td>\n",
       "      <td>(specialized, 1256.84)</td>\n",
       "      <td>(methodical, 1308.73)</td>\n",
       "      <td>(structured, 1348.41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(precise, 1373.07)</td>\n",
       "      <td>(disciplined, 1234.1)</td>\n",
       "      <td>(methodical, 1474.65)</td>\n",
       "      <td>(patient, 1047.3)</td>\n",
       "      <td>(concrete, 1408.74)</td>\n",
       "      <td>(factual, 1263.91)</td>\n",
       "      <td>(disciplined, 1306.7)</td>\n",
       "      <td>(concrete, 1211.54)</td>\n",
       "      <td>(balanced, 1228.65)</td>\n",
       "      <td>(intellectual, 1291.15)</td>\n",
       "      <td>(methodical, 1296.35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(practical, 1371.09)</td>\n",
       "      <td>(methodical, 1221.79)</td>\n",
       "      <td>(analytical, 1473.21)</td>\n",
       "      <td>(concrete, 1046.5)</td>\n",
       "      <td>(objective, 1382.89)</td>\n",
       "      <td>(straightforward, 1263.36)</td>\n",
       "      <td>(objective, 1295.28)</td>\n",
       "      <td>(intellectual, 1209.01)</td>\n",
       "      <td>(structured, 1225.15)</td>\n",
       "      <td>(concrete, 1279.02)</td>\n",
       "      <td>(systematic, 1279.38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(methodical, 1334.38)</td>\n",
       "      <td>(declarative, 1214.02)</td>\n",
       "      <td>(logical, 1417.45)</td>\n",
       "      <td>(impulsive, 1045.31)</td>\n",
       "      <td>(precise, 1367.73)</td>\n",
       "      <td>(precise, 1262.0)</td>\n",
       "      <td>(holistic, 1291.33)</td>\n",
       "      <td>(traditional, 1198.88)</td>\n",
       "      <td>(systematic, 1220.42)</td>\n",
       "      <td>(academic, 1259.69)</td>\n",
       "      <td>(pragmatic, 1277.61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(rational, 1332.24)</td>\n",
       "      <td>(pragmatic, 1193.8)</td>\n",
       "      <td>(academic, 1408.79)</td>\n",
       "      <td>(impatient, 1044.43)</td>\n",
       "      <td>(analytical, 1344.74)</td>\n",
       "      <td>(structured, 1257.57)</td>\n",
       "      <td>(precise, 1289.39)</td>\n",
       "      <td>(detached, 1197.47)</td>\n",
       "      <td>(perfectionist, 1206.55)</td>\n",
       "      <td>(analytical, 1257.94)</td>\n",
       "      <td>(straightforward, 1272.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(systematic, 1325.0)</td>\n",
       "      <td>(concrete, 1190.19)</td>\n",
       "      <td>(technical, 1400.67)</td>\n",
       "      <td>(reflective, 1043.74)</td>\n",
       "      <td>(intellectual, 1340.71)</td>\n",
       "      <td>(logical, 1254.62)</td>\n",
       "      <td>(concrete, 1285.51)</td>\n",
       "      <td>(poetic, 1197.13)</td>\n",
       "      <td>(confident, 1195.86)</td>\n",
       "      <td>(factual, 1247.35)</td>\n",
       "      <td>(literal, 1268.44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(cooperative, 1310.57)</td>\n",
       "      <td>(academic, 1188.15)</td>\n",
       "      <td>(elaborate, 1395.0)</td>\n",
       "      <td>(futuristic, 1032.0)</td>\n",
       "      <td>(factual, 1335.57)</td>\n",
       "      <td>(analytical, 1228.8)</td>\n",
       "      <td>(nuanced, 1271.18)</td>\n",
       "      <td>(precise, 1184.62)</td>\n",
       "      <td>(concrete, 1189.38)</td>\n",
       "      <td>(systematic, 1246.5)</td>\n",
       "      <td>(objective, 1267.87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(balanced, 1305.31)</td>\n",
       "      <td>(flexible, 1185.19)</td>\n",
       "      <td>(intellectual, 1374.76)</td>\n",
       "      <td>(grounding, 1032.0)</td>\n",
       "      <td>(systematic, 1331.94)</td>\n",
       "      <td>(contemporary, 1224.05)</td>\n",
       "      <td>(calm, 1258.18)</td>\n",
       "      <td>(objective, 1182.44)</td>\n",
       "      <td>(objective, 1179.3)</td>\n",
       "      <td>(specialized, 1239.08)</td>\n",
       "      <td>(focused, 1250.06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(disciplined, 1296.55)</td>\n",
       "      <td>(practical, 1185.13)</td>\n",
       "      <td>(precise, 1372.92)</td>\n",
       "      <td>(practical, 1031.97)</td>\n",
       "      <td>(realistic, 1315.13)</td>\n",
       "      <td>(intellectual, 1218.62)</td>\n",
       "      <td>(technical, 1258.05)</td>\n",
       "      <td>(disciplined, 1180.73)</td>\n",
       "      <td>(imaginative, 1169.95)</td>\n",
       "      <td>(disciplined, 1230.05)</td>\n",
       "      <td>(factual, 1248.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(intellectual, 1291.66)</td>\n",
       "      <td>(straightforward, 1181.68)</td>\n",
       "      <td>(wise, 1354.94)</td>\n",
       "      <td>(imaginative, 1031.94)</td>\n",
       "      <td>(elaborate, 1314.55)</td>\n",
       "      <td>(concise, 1214.76)</td>\n",
       "      <td>(analytical, 1248.63)</td>\n",
       "      <td>(rational, 1178.19)</td>\n",
       "      <td>(analytical, 1168.8)</td>\n",
       "      <td>(authoritative, 1229.29)</td>\n",
       "      <td>(empirical, 1225.57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(analytical, 1287.28)</td>\n",
       "      <td>(calm, 1174.64)</td>\n",
       "      <td>(nuanced, 1338.77)</td>\n",
       "      <td>(strategic, 1031.26)</td>\n",
       "      <td>(practical, 1311.35)</td>\n",
       "      <td>(systematic, 1212.55)</td>\n",
       "      <td>(straightforward, 1247.51)</td>\n",
       "      <td>(formal, 1174.0)</td>\n",
       "      <td>(calm, 1161.76)</td>\n",
       "      <td>(objective, 1223.02)</td>\n",
       "      <td>(declarative, 1218.51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(elaborate, 1286.91)</td>\n",
       "      <td>(formal, 1173.44)</td>\n",
       "      <td>(pragmatic, 1333.01)</td>\n",
       "      <td>(questioning, 1031.26)</td>\n",
       "      <td>(rational, 1310.85)</td>\n",
       "      <td>(objective, 1212.45)</td>\n",
       "      <td>(literal, 1227.38)</td>\n",
       "      <td>(direct, 1173.87)</td>\n",
       "      <td>(metaphorical, 1156.33)</td>\n",
       "      <td>(realistic, 1211.61)</td>\n",
       "      <td>(rational, 1214.59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(declarative, 1259.92)</td>\n",
       "      <td>(analytical, 1172.35)</td>\n",
       "      <td>(practical, 1322.37)</td>\n",
       "      <td>(satisficing, 1031.23)</td>\n",
       "      <td>(straightforward, 1303.62)</td>\n",
       "      <td>(practical, 1207.17)</td>\n",
       "      <td>(realistic, 1227.17)</td>\n",
       "      <td>(technical, 1173.77)</td>\n",
       "      <td>(rational, 1152.28)</td>\n",
       "      <td>(confident, 1202.07)</td>\n",
       "      <td>(analytical, 1211.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(logical, 1258.79)</td>\n",
       "      <td>(wise, 1170.79)</td>\n",
       "      <td>(formal, 1320.13)</td>\n",
       "      <td>(rational, 1031.23)</td>\n",
       "      <td>(perfectionist, 1296.14)</td>\n",
       "      <td>(balanced, 1206.17)</td>\n",
       "      <td>(specialized, 1214.4)</td>\n",
       "      <td>(logical, 1173.75)</td>\n",
       "      <td>(methodical, 1146.07)</td>\n",
       "      <td>(poetic, 1194.68)</td>\n",
       "      <td>(specialized, 1208.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(reflective, 1251.58)</td>\n",
       "      <td>(factual, 1164.64)</td>\n",
       "      <td>(strategic, 1298.75)</td>\n",
       "      <td>(respectful, 1030.56)</td>\n",
       "      <td>(specialized, 1287.31)</td>\n",
       "      <td>(grounding, 1205.92)</td>\n",
       "      <td>(declarative, 1212.9)</td>\n",
       "      <td>(cooperative, 1168.1)</td>\n",
       "      <td>(direct, 1143.22)</td>\n",
       "      <td>(elaborate, 1194.4)</td>\n",
       "      <td>(grounding, 1207.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(pragmatic, 1244.39)</td>\n",
       "      <td>(prosaic, 1163.29)</td>\n",
       "      <td>(objective, 1297.73)</td>\n",
       "      <td>(tentative, 1030.56)</td>\n",
       "      <td>(logical, 1286.9)</td>\n",
       "      <td>(declarative, 1196.49)</td>\n",
       "      <td>(focused, 1197.86)</td>\n",
       "      <td>(adaptable, 1162.53)</td>\n",
       "      <td>(prosaic, 1139.64)</td>\n",
       "      <td>(rational, 1189.54)</td>\n",
       "      <td>(formal, 1204.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(nuanced, 1244.37)</td>\n",
       "      <td>(rational, 1154.85)</td>\n",
       "      <td>(tactical, 1272.87)</td>\n",
       "      <td>(flexible, 1030.56)</td>\n",
       "      <td>(wise, 1275.85)</td>\n",
       "      <td>(literal, 1189.69)</td>\n",
       "      <td>(intellectual, 1196.76)</td>\n",
       "      <td>(factual, 1159.22)</td>\n",
       "      <td>(formal, 1135.99)</td>\n",
       "      <td>(practical, 1188.86)</td>\n",
       "      <td>(serious, 1202.53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(academic, 1242.66)</td>\n",
       "      <td>(objective, 1151.97)</td>\n",
       "      <td>(contemplative, 1270.35)</td>\n",
       "      <td>(tactical, 1030.53)</td>\n",
       "      <td>(learning, 1270.12)</td>\n",
       "      <td>(academic, 1181.97)</td>\n",
       "      <td>(logical, 1194.97)</td>\n",
       "      <td>(agreeable, 1141.55)</td>\n",
       "      <td>(technical, 1133.24)</td>\n",
       "      <td>(pragmatic, 1187.33)</td>\n",
       "      <td>(disciplined, 1202.33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(straightforward, 1235.25)</td>\n",
       "      <td>(scholarly, 1148.92)</td>\n",
       "      <td>(factual, 1265.06)</td>\n",
       "      <td>(arrogant, 1030.53)</td>\n",
       "      <td>(formal, 1262.08)</td>\n",
       "      <td>(confident, 1180.62)</td>\n",
       "      <td>(harmonious, 1192.23)</td>\n",
       "      <td>(grounding, 1132.22)</td>\n",
       "      <td>(logical, 1129.34)</td>\n",
       "      <td>(declarative, 1185.16)</td>\n",
       "      <td>(prosaic, 1186.41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(focused, 1223.93)</td>\n",
       "      <td>(concise, 1148.02)</td>\n",
       "      <td>(pedantic, 1255.78)</td>\n",
       "      <td>(determined, 1030.53)</td>\n",
       "      <td>(balanced, 1261.02)</td>\n",
       "      <td>(focused, 1180.32)</td>\n",
       "      <td>(wise, 1189.94)</td>\n",
       "      <td>(declarative, 1123.03)</td>\n",
       "      <td>(realistic, 1125.83)</td>\n",
       "      <td>(logical, 1172.31)</td>\n",
       "      <td>(elaborate, 1178.65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(factual, 1220.74)</td>\n",
       "      <td>(authoritative, 1143.93)</td>\n",
       "      <td>(disciplined, 1254.4)</td>\n",
       "      <td>(concise, 1029.96)</td>\n",
       "      <td>(pragmatic, 1246.29)</td>\n",
       "      <td>(disciplined, 1176.71)</td>\n",
       "      <td>(scholarly, 1185.55)</td>\n",
       "      <td>(reflective, 1121.72)</td>\n",
       "      <td>(reflective, 1119.17)</td>\n",
       "      <td>(cooperative, 1163.1)</td>\n",
       "      <td>(technical, 1171.16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(wise, 1216.26)</td>\n",
       "      <td>(balanced, 1143.29)</td>\n",
       "      <td>(collaborative, 1254.07)</td>\n",
       "      <td>(nostalgic, 1029.29)</td>\n",
       "      <td>(technical, 1243.14)</td>\n",
       "      <td>(cooperative, 1176.49)</td>\n",
       "      <td>(learning, 1179.47)</td>\n",
       "      <td>(excitable, 1120.46)</td>\n",
       "      <td>(pragmatic, 1118.21)</td>\n",
       "      <td>(empirical, 1155.17)</td>\n",
       "      <td>(respectful, 1168.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(realistic, 1214.99)</td>\n",
       "      <td>(precise, 1141.49)</td>\n",
       "      <td>(specialized, 1253.86)</td>\n",
       "      <td>(abstract, 1028.11)</td>\n",
       "      <td>(academic, 1240.64)</td>\n",
       "      <td>(technical, 1172.72)</td>\n",
       "      <td>(practical, 1177.62)</td>\n",
       "      <td>(serious, 1118.79)</td>\n",
       "      <td>(detached, 1113.73)</td>\n",
       "      <td>(warm, 1149.1)</td>\n",
       "      <td>(logical, 1163.26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(objective, 1208.8)</td>\n",
       "      <td>(intellectual, 1140.81)</td>\n",
       "      <td>(rational, 1245.85)</td>\n",
       "      <td>(emotional, 1016.83)</td>\n",
       "      <td>(cooperative, 1235.24)</td>\n",
       "      <td>(empirical, 1165.09)</td>\n",
       "      <td>(elaborate, 1176.9)</td>\n",
       "      <td>(analytical, 1115.4)</td>\n",
       "      <td>(focused, 1113.55)</td>\n",
       "      <td>(scholarly, 1146.24)</td>\n",
       "      <td>(traditional, 1152.63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(holistic, 1205.22)</td>\n",
       "      <td>(detached, 1138.16)</td>\n",
       "      <td>(straightforward, 1240.32)</td>\n",
       "      <td>(playful, 1016.74)</td>\n",
       "      <td>(grounding, 1233.17)</td>\n",
       "      <td>(methodical, 1162.05)</td>\n",
       "      <td>(organic, 1172.68)</td>\n",
       "      <td>(cautious, 1111.75)</td>\n",
       "      <td>(literal, 1107.63)</td>\n",
       "      <td>(technical, 1137.57)</td>\n",
       "      <td>(practical, 1152.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(specialized, 1203.92)</td>\n",
       "      <td>(adaptable, 1134.76)</td>\n",
       "      <td>(focused, 1239.05)</td>\n",
       "      <td>(encouraging, 1016.74)</td>\n",
       "      <td>(authoritative, 1233.12)</td>\n",
       "      <td>(realistic, 1147.76)</td>\n",
       "      <td>(authoritative, 1171.21)</td>\n",
       "      <td>(flexible, 1110.74)</td>\n",
       "      <td>(bold, 1107.02)</td>\n",
       "      <td>(focused, 1136.55)</td>\n",
       "      <td>(simplistic, 1147.65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(literal, 1195.05)</td>\n",
       "      <td>(confident, 1129.59)</td>\n",
       "      <td>(concrete, 1223.74)</td>\n",
       "      <td>(improvisational, 1016.67)</td>\n",
       "      <td>(focused, 1229.59)</td>\n",
       "      <td>(scholarly, 1142.99)</td>\n",
       "      <td>(rational, 1170.04)</td>\n",
       "      <td>(focused, 1103.73)</td>\n",
       "      <td>(practical, 1103.28)</td>\n",
       "      <td>(enthusiastic, 1132.11)</td>\n",
       "      <td>(direct, 1147.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(contemplative, 1184.07)</td>\n",
       "      <td>(focused, 1125.35)</td>\n",
       "      <td>(cooperative, 1213.67)</td>\n",
       "      <td>(objective, 1016.67)</td>\n",
       "      <td>(patient, 1226.38)</td>\n",
       "      <td>(casual, 1141.58)</td>\n",
       "      <td>(factual, 1168.89)</td>\n",
       "      <td>(systematic, 1102.78)</td>\n",
       "      <td>(unapologetic, 1102.92)</td>\n",
       "      <td>(nuanced, 1131.01)</td>\n",
       "      <td>(cooperative, 1146.87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(learning, 1180.11)</td>\n",
       "      <td>(reflective, 1124.06)</td>\n",
       "      <td>(philosophical, 1203.98)</td>\n",
       "      <td>(stoic, 1016.54)</td>\n",
       "      <td>(confident, 1220.77)</td>\n",
       "      <td>(calm, 1139.47)</td>\n",
       "      <td>(direct, 1165.98)</td>\n",
       "      <td>(irreverent, 1102.09)</td>\n",
       "      <td>(traditional, 1101.14)</td>\n",
       "      <td>(blunt, 1127.66)</td>\n",
       "      <td>(balanced, 1146.58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(supportive, 1177.27)</td>\n",
       "      <td>(minimalist, 1117.88)</td>\n",
       "      <td>(calm, 1201.18)</td>\n",
       "      <td>(systematic, 1016.07)</td>\n",
       "      <td>(declarative, 1220.57)</td>\n",
       "      <td>(detached, 1139.39)</td>\n",
       "      <td>(formal, 1155.23)</td>\n",
       "      <td>(straightforward, 1101.37)</td>\n",
       "      <td>(holistic, 1099.47)</td>\n",
       "      <td>(straightforward, 1124.84)</td>\n",
       "      <td>(confident, 1136.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(prosaic, 1169.34)</td>\n",
       "      <td>(cooperative, 1117.77)</td>\n",
       "      <td>(confident, 1196.39)</td>\n",
       "      <td>(leisurely, 1016.04)</td>\n",
       "      <td>(calm, 1219.55)</td>\n",
       "      <td>(serious, 1133.57)</td>\n",
       "      <td>(academic, 1152.83)</td>\n",
       "      <td>(pragmatic, 1099.91)</td>\n",
       "      <td>(universal, 1098.93)</td>\n",
       "      <td>(reflective, 1122.36)</td>\n",
       "      <td>(detached, 1135.93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(confident, 1166.71)</td>\n",
       "      <td>(direct, 1114.43)</td>\n",
       "      <td>(creative, 1195.0)</td>\n",
       "      <td>(skeptical, 1016.04)</td>\n",
       "      <td>(strategic, 1215.52)</td>\n",
       "      <td>(adaptable, 1132.34)</td>\n",
       "      <td>(detached, 1142.82)</td>\n",
       "      <td>(empirical, 1098.67)</td>\n",
       "      <td>(patient, 1096.28)</td>\n",
       "      <td>(excitable, 1116.13)</td>\n",
       "      <td>(collaborative, 1127.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(collaborative, 1166.62)</td>\n",
       "      <td>(realistic, 1107.86)</td>\n",
       "      <td>(reflective, 1194.41)</td>\n",
       "      <td>(detached, 1016.03)</td>\n",
       "      <td>(respectful, 1208.3)</td>\n",
       "      <td>(prosaic, 1130.56)</td>\n",
       "      <td>(cooperative, 1139.2)</td>\n",
       "      <td>(realistic, 1097.54)</td>\n",
       "      <td>(agreeable, 1089.53)</td>\n",
       "      <td>(minimalist, 1110.15)</td>\n",
       "      <td>(minimalist, 1121.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(empirical, 1164.21)</td>\n",
       "      <td>(grounding, 1104.49)</td>\n",
       "      <td>(verbose, 1184.35)</td>\n",
       "      <td>(intellectual, 1016.0)</td>\n",
       "      <td>(prosaic, 1193.7)</td>\n",
       "      <td>(patient, 1128.05)</td>\n",
       "      <td>(pragmatic, 1138.28)</td>\n",
       "      <td>(leisurely, 1095.44)</td>\n",
       "      <td>(tactical, 1088.91)</td>\n",
       "      <td>(direct, 1104.86)</td>\n",
       "      <td>(calm, 1118.94)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(serious, 1160.35)</td>\n",
       "      <td>(contemplative, 1100.94)</td>\n",
       "      <td>(decisive, 1175.81)</td>\n",
       "      <td>(intuitive, 1016.0)</td>\n",
       "      <td>(universal, 1187.93)</td>\n",
       "      <td>(elaborate, 1126.31)</td>\n",
       "      <td>(gentle, 1134.4)</td>\n",
       "      <td>(supportive, 1087.76)</td>\n",
       "      <td>(cooperative, 1085.15)</td>\n",
       "      <td>(colloquial, 1104.01)</td>\n",
       "      <td>(tactical, 1116.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(technical, 1154.48)</td>\n",
       "      <td>(empirical, 1099.84)</td>\n",
       "      <td>(visionary, 1173.48)</td>\n",
       "      <td>(metaphorical, 1016.0)</td>\n",
       "      <td>(holistic, 1178.21)</td>\n",
       "      <td>(specialized, 1107.38)</td>\n",
       "      <td>(respectful, 1130.11)</td>\n",
       "      <td>(deferential, 1087.62)</td>\n",
       "      <td>(contemporary, 1083.87)</td>\n",
       "      <td>(formal, 1103.61)</td>\n",
       "      <td>(academic, 1116.28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(formal, 1135.93)</td>\n",
       "      <td>(patient, 1097.93)</td>\n",
       "      <td>(supportive, 1167.96)</td>\n",
       "      <td>(focused, 1016.0)</td>\n",
       "      <td>(scholarly, 1178.14)</td>\n",
       "      <td>(decisive, 1105.55)</td>\n",
       "      <td>(grounding, 1127.92)</td>\n",
       "      <td>(prosaic, 1085.17)</td>\n",
       "      <td>(straightforward, 1077.73)</td>\n",
       "      <td>(encouraging, 1100.84)</td>\n",
       "      <td>(intellectual, 1114.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(detached, 1130.77)</td>\n",
       "      <td>(contemporary, 1097.8)</td>\n",
       "      <td>(literal, 1161.27)</td>\n",
       "      <td>(artistic, 1016.0)</td>\n",
       "      <td>(serious, 1177.44)</td>\n",
       "      <td>(innovative, 1103.01)</td>\n",
       "      <td>(patient, 1125.45)</td>\n",
       "      <td>(bold, 1084.94)</td>\n",
       "      <td>(empirical, 1072.2)</td>\n",
       "      <td>(serious, 1098.56)</td>\n",
       "      <td>(contemporary, 1113.38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(calm, 1124.19)</td>\n",
       "      <td>(technical, 1097.42)</td>\n",
       "      <td>(poetic, 1160.91)</td>\n",
       "      <td>(reserved, 1015.72)</td>\n",
       "      <td>(adaptable, 1174.29)</td>\n",
       "      <td>(enthusiastic, 1098.77)</td>\n",
       "      <td>(assertive, 1111.77)</td>\n",
       "      <td>(minimalist, 1083.33)</td>\n",
       "      <td>(intellectual, 1071.02)</td>\n",
       "      <td>(supportive, 1097.83)</td>\n",
       "      <td>(concise, 1112.31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(contemporary, 1120.72)</td>\n",
       "      <td>(serious, 1093.39)</td>\n",
       "      <td>(encouraging, 1148.48)</td>\n",
       "      <td>(balanced, 1015.2)</td>\n",
       "      <td>(verbose, 1172.99)</td>\n",
       "      <td>(assertive, 1098.35)</td>\n",
       "      <td>(concise, 1107.64)</td>\n",
       "      <td>(strategic, 1082.76)</td>\n",
       "      <td>(simplistic, 1067.12)</td>\n",
       "      <td>(assertive, 1095.8)</td>\n",
       "      <td>(universal, 1110.89)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(stoic, 1116.68)</td>\n",
       "      <td>(nuanced, 1092.8)</td>\n",
       "      <td>(concise, 1141.42)</td>\n",
       "      <td>(deferential, 1012.4)</td>\n",
       "      <td>(tactical, 1169.74)</td>\n",
       "      <td>(authoritative, 1096.14)</td>\n",
       "      <td>(confident, 1105.01)</td>\n",
       "      <td>(reserved, 1082.07)</td>\n",
       "      <td>(nuanced, 1063.99)</td>\n",
       "      <td>(grounding, 1084.2)</td>\n",
       "      <td>(stoic, 1110.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(flexible, 1113.31)</td>\n",
       "      <td>(progressive, 1092.36)</td>\n",
       "      <td>(perfectionist, 1139.27)</td>\n",
       "      <td>(ethical, 1002.2)</td>\n",
       "      <td>(literal, 1163.08)</td>\n",
       "      <td>(nuanced, 1095.97)</td>\n",
       "      <td>(decisive, 1102.9)</td>\n",
       "      <td>(casual, 1080.31)</td>\n",
       "      <td>(declarative, 1063.28)</td>\n",
       "      <td>(concise, 1066.36)</td>\n",
       "      <td>(adaptable, 1106.28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(patient, 1112.99)</td>\n",
       "      <td>(perfectionist, 1091.42)</td>\n",
       "      <td>(direct, 1136.78)</td>\n",
       "      <td>(contemporary, 1002.08)</td>\n",
       "      <td>(empirical, 1154.59)</td>\n",
       "      <td>(colloquial, 1092.1)</td>\n",
       "      <td>(perfectionist, 1093.96)</td>\n",
       "      <td>(diplomatic, 1079.46)</td>\n",
       "      <td>(serious, 1062.2)</td>\n",
       "      <td>(collaborative, 1064.76)</td>\n",
       "      <td>(authoritative, 1085.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(authoritative, 1110.32)</td>\n",
       "      <td>(logical, 1091.33)</td>\n",
       "      <td>(empirical, 1133.75)</td>\n",
       "      <td>(approximate, 1002.07)</td>\n",
       "      <td>(cautious, 1146.63)</td>\n",
       "      <td>(cool, 1090.49)</td>\n",
       "      <td>(balanced, 1092.29)</td>\n",
       "      <td>(confident, 1072.14)</td>\n",
       "      <td>(innovative, 1062.08)</td>\n",
       "      <td>(tactical, 1062.51)</td>\n",
       "      <td>(conservative, 1085.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(colloquial, 1108.84)</td>\n",
       "      <td>(specialized, 1085.76)</td>\n",
       "      <td>(balanced, 1128.98)</td>\n",
       "      <td>(conservative, 1001.21)</td>\n",
       "      <td>(nuanced, 1136.75)</td>\n",
       "      <td>(universal, 1087.47)</td>\n",
       "      <td>(empirical, 1087.53)</td>\n",
       "      <td>(balanced, 1072.11)</td>\n",
       "      <td>(casual, 1061.77)</td>\n",
       "      <td>(arrogant, 1061.08)</td>\n",
       "      <td>(wise, 1077.85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(strategic, 1105.52)</td>\n",
       "      <td>(holistic, 1083.91)</td>\n",
       "      <td>(declarative, 1128.88)</td>\n",
       "      <td>(wise, 1000.83)</td>\n",
       "      <td>(gentle, 1130.03)</td>\n",
       "      <td>(respectful, 1084.92)</td>\n",
       "      <td>(innovative, 1084.86)</td>\n",
       "      <td>(authoritative, 1068.9)</td>\n",
       "      <td>(factual, 1059.53)</td>\n",
       "      <td>(playful, 1060.05)</td>\n",
       "      <td>(scholarly, 1076.85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(respectful, 1104.9)</td>\n",
       "      <td>(harmonious, 1078.69)</td>\n",
       "      <td>(realistic, 1126.94)</td>\n",
       "      <td>(curious, 1000.77)</td>\n",
       "      <td>(contemporary, 1126.79)</td>\n",
       "      <td>(warm, 1076.57)</td>\n",
       "      <td>(serious, 1082.98)</td>\n",
       "      <td>(tactical, 1062.01)</td>\n",
       "      <td>(excitable, 1057.3)</td>\n",
       "      <td>(optimistic, 1056.58)</td>\n",
       "      <td>(reserved, 1076.83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(traditional, 1102.55)</td>\n",
       "      <td>(reserved, 1074.04)</td>\n",
       "      <td>(serious, 1122.81)</td>\n",
       "      <td>(analytical, 1000.74)</td>\n",
       "      <td>(direct, 1123.76)</td>\n",
       "      <td>(learning, 1075.82)</td>\n",
       "      <td>(supportive, 1082.32)</td>\n",
       "      <td>(blunt, 1060.86)</td>\n",
       "      <td>(authoritative, 1056.99)</td>\n",
       "      <td>(casual, 1052.93)</td>\n",
       "      <td>(determined, 1073.44)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              claude-haiku-4.5               deepseek-v3.2  \\\n",
       "0          (concrete, 1420.41)          (literal, 1289.51)   \n",
       "1        (structured, 1408.72)       (structured, 1276.91)   \n",
       "2         (grounding, 1378.89)        (systematic, 1265.3)   \n",
       "3           (precise, 1373.07)       (disciplined, 1234.1)   \n",
       "4         (practical, 1371.09)       (methodical, 1221.79)   \n",
       "5        (methodical, 1334.38)      (declarative, 1214.02)   \n",
       "6          (rational, 1332.24)         (pragmatic, 1193.8)   \n",
       "7         (systematic, 1325.0)         (concrete, 1190.19)   \n",
       "8       (cooperative, 1310.57)         (academic, 1188.15)   \n",
       "9          (balanced, 1305.31)         (flexible, 1185.19)   \n",
       "10      (disciplined, 1296.55)        (practical, 1185.13)   \n",
       "11     (intellectual, 1291.66)  (straightforward, 1181.68)   \n",
       "12       (analytical, 1287.28)             (calm, 1174.64)   \n",
       "13        (elaborate, 1286.91)           (formal, 1173.44)   \n",
       "14      (declarative, 1259.92)       (analytical, 1172.35)   \n",
       "15          (logical, 1258.79)             (wise, 1170.79)   \n",
       "16       (reflective, 1251.58)          (factual, 1164.64)   \n",
       "17        (pragmatic, 1244.39)          (prosaic, 1163.29)   \n",
       "18          (nuanced, 1244.37)         (rational, 1154.85)   \n",
       "19         (academic, 1242.66)        (objective, 1151.97)   \n",
       "20  (straightforward, 1235.25)        (scholarly, 1148.92)   \n",
       "21          (focused, 1223.93)          (concise, 1148.02)   \n",
       "22          (factual, 1220.74)    (authoritative, 1143.93)   \n",
       "23             (wise, 1216.26)         (balanced, 1143.29)   \n",
       "24        (realistic, 1214.99)          (precise, 1141.49)   \n",
       "25         (objective, 1208.8)     (intellectual, 1140.81)   \n",
       "26         (holistic, 1205.22)         (detached, 1138.16)   \n",
       "27      (specialized, 1203.92)        (adaptable, 1134.76)   \n",
       "28          (literal, 1195.05)        (confident, 1129.59)   \n",
       "29    (contemplative, 1184.07)          (focused, 1125.35)   \n",
       "30         (learning, 1180.11)       (reflective, 1124.06)   \n",
       "31       (supportive, 1177.27)       (minimalist, 1117.88)   \n",
       "32          (prosaic, 1169.34)      (cooperative, 1117.77)   \n",
       "33        (confident, 1166.71)           (direct, 1114.43)   \n",
       "34    (collaborative, 1166.62)        (realistic, 1107.86)   \n",
       "35        (empirical, 1164.21)        (grounding, 1104.49)   \n",
       "36          (serious, 1160.35)    (contemplative, 1100.94)   \n",
       "37        (technical, 1154.48)        (empirical, 1099.84)   \n",
       "38           (formal, 1135.93)          (patient, 1097.93)   \n",
       "39         (detached, 1130.77)      (contemporary, 1097.8)   \n",
       "40             (calm, 1124.19)        (technical, 1097.42)   \n",
       "41     (contemporary, 1120.72)          (serious, 1093.39)   \n",
       "42            (stoic, 1116.68)           (nuanced, 1092.8)   \n",
       "43         (flexible, 1113.31)      (progressive, 1092.36)   \n",
       "44          (patient, 1112.99)    (perfectionist, 1091.42)   \n",
       "45    (authoritative, 1110.32)          (logical, 1091.33)   \n",
       "46       (colloquial, 1108.84)      (specialized, 1085.76)   \n",
       "47        (strategic, 1105.52)         (holistic, 1083.91)   \n",
       "48        (respectful, 1104.9)       (harmonious, 1078.69)   \n",
       "49      (traditional, 1102.55)         (reserved, 1074.04)   \n",
       "\n",
       "        gemini-3-flash-preview               gemma-3-4b-it  \\\n",
       "0        (structured, 1556.26)      (declarative, 1071.51)   \n",
       "1        (systematic, 1520.18)           (gentle, 1061.13)   \n",
       "2         (scholarly, 1504.46)          (precise, 1059.77)   \n",
       "3        (methodical, 1474.65)           (patient, 1047.3)   \n",
       "4        (analytical, 1473.21)          (concrete, 1046.5)   \n",
       "5           (logical, 1417.45)        (impulsive, 1045.31)   \n",
       "6          (academic, 1408.79)        (impatient, 1044.43)   \n",
       "7         (technical, 1400.67)       (reflective, 1043.74)   \n",
       "8          (elaborate, 1395.0)        (futuristic, 1032.0)   \n",
       "9      (intellectual, 1374.76)         (grounding, 1032.0)   \n",
       "10          (precise, 1372.92)        (practical, 1031.97)   \n",
       "11             (wise, 1354.94)      (imaginative, 1031.94)   \n",
       "12          (nuanced, 1338.77)        (strategic, 1031.26)   \n",
       "13        (pragmatic, 1333.01)      (questioning, 1031.26)   \n",
       "14        (practical, 1322.37)      (satisficing, 1031.23)   \n",
       "15           (formal, 1320.13)         (rational, 1031.23)   \n",
       "16        (strategic, 1298.75)       (respectful, 1030.56)   \n",
       "17        (objective, 1297.73)        (tentative, 1030.56)   \n",
       "18         (tactical, 1272.87)         (flexible, 1030.56)   \n",
       "19    (contemplative, 1270.35)         (tactical, 1030.53)   \n",
       "20          (factual, 1265.06)         (arrogant, 1030.53)   \n",
       "21         (pedantic, 1255.78)       (determined, 1030.53)   \n",
       "22       (disciplined, 1254.4)          (concise, 1029.96)   \n",
       "23    (collaborative, 1254.07)        (nostalgic, 1029.29)   \n",
       "24      (specialized, 1253.86)         (abstract, 1028.11)   \n",
       "25         (rational, 1245.85)        (emotional, 1016.83)   \n",
       "26  (straightforward, 1240.32)          (playful, 1016.74)   \n",
       "27          (focused, 1239.05)      (encouraging, 1016.74)   \n",
       "28         (concrete, 1223.74)  (improvisational, 1016.67)   \n",
       "29      (cooperative, 1213.67)        (objective, 1016.67)   \n",
       "30    (philosophical, 1203.98)            (stoic, 1016.54)   \n",
       "31             (calm, 1201.18)       (systematic, 1016.07)   \n",
       "32        (confident, 1196.39)        (leisurely, 1016.04)   \n",
       "33          (creative, 1195.0)        (skeptical, 1016.04)   \n",
       "34       (reflective, 1194.41)         (detached, 1016.03)   \n",
       "35          (verbose, 1184.35)      (intellectual, 1016.0)   \n",
       "36         (decisive, 1175.81)         (intuitive, 1016.0)   \n",
       "37        (visionary, 1173.48)      (metaphorical, 1016.0)   \n",
       "38       (supportive, 1167.96)           (focused, 1016.0)   \n",
       "39          (literal, 1161.27)          (artistic, 1016.0)   \n",
       "40           (poetic, 1160.91)         (reserved, 1015.72)   \n",
       "41      (encouraging, 1148.48)          (balanced, 1015.2)   \n",
       "42          (concise, 1141.42)       (deferential, 1012.4)   \n",
       "43    (perfectionist, 1139.27)           (ethical, 1002.2)   \n",
       "44           (direct, 1136.78)     (contemporary, 1002.08)   \n",
       "45        (empirical, 1133.75)      (approximate, 1002.07)   \n",
       "46         (balanced, 1128.98)     (conservative, 1001.21)   \n",
       "47      (declarative, 1128.88)             (wise, 1000.83)   \n",
       "48        (realistic, 1126.94)          (curious, 1000.77)   \n",
       "49          (serious, 1122.81)       (analytical, 1000.74)   \n",
       "\n",
       "                       gpt-5.1               grok-4.1-fast  \\\n",
       "0        (structured, 1494.34)         (concrete, 1338.84)   \n",
       "1       (disciplined, 1445.78)        (pragmatic, 1291.51)   \n",
       "2        (methodical, 1436.45)         (rational, 1273.38)   \n",
       "3          (concrete, 1408.74)          (factual, 1263.91)   \n",
       "4         (objective, 1382.89)  (straightforward, 1263.36)   \n",
       "5           (precise, 1367.73)           (precise, 1262.0)   \n",
       "6        (analytical, 1344.74)       (structured, 1257.57)   \n",
       "7      (intellectual, 1340.71)          (logical, 1254.62)   \n",
       "8           (factual, 1335.57)        (analytical, 1228.8)   \n",
       "9        (systematic, 1331.94)     (contemporary, 1224.05)   \n",
       "10        (realistic, 1315.13)     (intellectual, 1218.62)   \n",
       "11        (elaborate, 1314.55)          (concise, 1214.76)   \n",
       "12        (practical, 1311.35)       (systematic, 1212.55)   \n",
       "13         (rational, 1310.85)        (objective, 1212.45)   \n",
       "14  (straightforward, 1303.62)        (practical, 1207.17)   \n",
       "15    (perfectionist, 1296.14)         (balanced, 1206.17)   \n",
       "16      (specialized, 1287.31)        (grounding, 1205.92)   \n",
       "17           (logical, 1286.9)      (declarative, 1196.49)   \n",
       "18             (wise, 1275.85)          (literal, 1189.69)   \n",
       "19         (learning, 1270.12)         (academic, 1181.97)   \n",
       "20           (formal, 1262.08)        (confident, 1180.62)   \n",
       "21         (balanced, 1261.02)          (focused, 1180.32)   \n",
       "22        (pragmatic, 1246.29)      (disciplined, 1176.71)   \n",
       "23        (technical, 1243.14)      (cooperative, 1176.49)   \n",
       "24         (academic, 1240.64)        (technical, 1172.72)   \n",
       "25      (cooperative, 1235.24)        (empirical, 1165.09)   \n",
       "26        (grounding, 1233.17)       (methodical, 1162.05)   \n",
       "27    (authoritative, 1233.12)        (realistic, 1147.76)   \n",
       "28          (focused, 1229.59)        (scholarly, 1142.99)   \n",
       "29          (patient, 1226.38)           (casual, 1141.58)   \n",
       "30        (confident, 1220.77)             (calm, 1139.47)   \n",
       "31      (declarative, 1220.57)         (detached, 1139.39)   \n",
       "32             (calm, 1219.55)          (serious, 1133.57)   \n",
       "33        (strategic, 1215.52)        (adaptable, 1132.34)   \n",
       "34        (respectful, 1208.3)          (prosaic, 1130.56)   \n",
       "35           (prosaic, 1193.7)          (patient, 1128.05)   \n",
       "36        (universal, 1187.93)        (elaborate, 1126.31)   \n",
       "37         (holistic, 1178.21)      (specialized, 1107.38)   \n",
       "38        (scholarly, 1178.14)         (decisive, 1105.55)   \n",
       "39          (serious, 1177.44)       (innovative, 1103.01)   \n",
       "40        (adaptable, 1174.29)     (enthusiastic, 1098.77)   \n",
       "41          (verbose, 1172.99)        (assertive, 1098.35)   \n",
       "42         (tactical, 1169.74)    (authoritative, 1096.14)   \n",
       "43          (literal, 1163.08)          (nuanced, 1095.97)   \n",
       "44        (empirical, 1154.59)        (colloquial, 1092.1)   \n",
       "45         (cautious, 1146.63)             (cool, 1090.49)   \n",
       "46          (nuanced, 1136.75)        (universal, 1087.47)   \n",
       "47           (gentle, 1130.03)       (respectful, 1084.92)   \n",
       "48     (contemporary, 1126.79)             (warm, 1076.57)   \n",
       "49           (direct, 1123.76)         (learning, 1075.82)   \n",
       "\n",
       "              kimi-k2-thinking                llama-3.1-8b  \\\n",
       "0        (methodical, 1351.57)       (structured, 1334.62)   \n",
       "1        (structured, 1349.27)       (methodical, 1257.69)   \n",
       "2        (systematic, 1323.84)      (specialized, 1230.36)   \n",
       "3        (disciplined, 1306.7)         (concrete, 1211.54)   \n",
       "4         (objective, 1295.28)     (intellectual, 1209.01)   \n",
       "5          (holistic, 1291.33)      (traditional, 1198.88)   \n",
       "6           (precise, 1289.39)         (detached, 1197.47)   \n",
       "7          (concrete, 1285.51)           (poetic, 1197.13)   \n",
       "8           (nuanced, 1271.18)          (precise, 1184.62)   \n",
       "9              (calm, 1258.18)        (objective, 1182.44)   \n",
       "10        (technical, 1258.05)      (disciplined, 1180.73)   \n",
       "11       (analytical, 1248.63)         (rational, 1178.19)   \n",
       "12  (straightforward, 1247.51)            (formal, 1174.0)   \n",
       "13          (literal, 1227.38)           (direct, 1173.87)   \n",
       "14        (realistic, 1227.17)        (technical, 1173.77)   \n",
       "15       (specialized, 1214.4)          (logical, 1173.75)   \n",
       "16       (declarative, 1212.9)       (cooperative, 1168.1)   \n",
       "17          (focused, 1197.86)        (adaptable, 1162.53)   \n",
       "18     (intellectual, 1196.76)          (factual, 1159.22)   \n",
       "19          (logical, 1194.97)        (agreeable, 1141.55)   \n",
       "20       (harmonious, 1192.23)        (grounding, 1132.22)   \n",
       "21             (wise, 1189.94)      (declarative, 1123.03)   \n",
       "22        (scholarly, 1185.55)       (reflective, 1121.72)   \n",
       "23         (learning, 1179.47)        (excitable, 1120.46)   \n",
       "24        (practical, 1177.62)          (serious, 1118.79)   \n",
       "25         (elaborate, 1176.9)        (analytical, 1115.4)   \n",
       "26          (organic, 1172.68)         (cautious, 1111.75)   \n",
       "27    (authoritative, 1171.21)         (flexible, 1110.74)   \n",
       "28         (rational, 1170.04)          (focused, 1103.73)   \n",
       "29          (factual, 1168.89)       (systematic, 1102.78)   \n",
       "30           (direct, 1165.98)       (irreverent, 1102.09)   \n",
       "31           (formal, 1155.23)  (straightforward, 1101.37)   \n",
       "32         (academic, 1152.83)        (pragmatic, 1099.91)   \n",
       "33         (detached, 1142.82)        (empirical, 1098.67)   \n",
       "34       (cooperative, 1139.2)        (realistic, 1097.54)   \n",
       "35        (pragmatic, 1138.28)        (leisurely, 1095.44)   \n",
       "36            (gentle, 1134.4)       (supportive, 1087.76)   \n",
       "37       (respectful, 1130.11)      (deferential, 1087.62)   \n",
       "38        (grounding, 1127.92)          (prosaic, 1085.17)   \n",
       "39          (patient, 1125.45)             (bold, 1084.94)   \n",
       "40        (assertive, 1111.77)       (minimalist, 1083.33)   \n",
       "41          (concise, 1107.64)        (strategic, 1082.76)   \n",
       "42        (confident, 1105.01)         (reserved, 1082.07)   \n",
       "43          (decisive, 1102.9)           (casual, 1080.31)   \n",
       "44    (perfectionist, 1093.96)       (diplomatic, 1079.46)   \n",
       "45         (balanced, 1092.29)        (confident, 1072.14)   \n",
       "46        (empirical, 1087.53)         (balanced, 1072.11)   \n",
       "47       (innovative, 1084.86)     (authoritative, 1068.9)   \n",
       "48          (serious, 1082.98)         (tactical, 1062.01)   \n",
       "49       (supportive, 1082.32)            (blunt, 1060.86)   \n",
       "\n",
       "            ministral-14b-2512 qwen3-vl-235b-a22b-thinking  \\\n",
       "0       (disciplined, 1263.86)       (structured, 1335.22)   \n",
       "1           (precise, 1262.73)          (precise, 1334.04)   \n",
       "2       (specialized, 1256.84)       (methodical, 1308.73)   \n",
       "3          (balanced, 1228.65)     (intellectual, 1291.15)   \n",
       "4        (structured, 1225.15)         (concrete, 1279.02)   \n",
       "5        (systematic, 1220.42)         (academic, 1259.69)   \n",
       "6     (perfectionist, 1206.55)       (analytical, 1257.94)   \n",
       "7         (confident, 1195.86)          (factual, 1247.35)   \n",
       "8          (concrete, 1189.38)        (systematic, 1246.5)   \n",
       "9          (objective, 1179.3)      (specialized, 1239.08)   \n",
       "10      (imaginative, 1169.95)      (disciplined, 1230.05)   \n",
       "11        (analytical, 1168.8)    (authoritative, 1229.29)   \n",
       "12             (calm, 1161.76)        (objective, 1223.02)   \n",
       "13     (metaphorical, 1156.33)        (realistic, 1211.61)   \n",
       "14         (rational, 1152.28)        (confident, 1202.07)   \n",
       "15       (methodical, 1146.07)           (poetic, 1194.68)   \n",
       "16           (direct, 1143.22)         (elaborate, 1194.4)   \n",
       "17          (prosaic, 1139.64)         (rational, 1189.54)   \n",
       "18           (formal, 1135.99)        (practical, 1188.86)   \n",
       "19        (technical, 1133.24)        (pragmatic, 1187.33)   \n",
       "20          (logical, 1129.34)      (declarative, 1185.16)   \n",
       "21        (realistic, 1125.83)          (logical, 1172.31)   \n",
       "22       (reflective, 1119.17)       (cooperative, 1163.1)   \n",
       "23        (pragmatic, 1118.21)        (empirical, 1155.17)   \n",
       "24         (detached, 1113.73)              (warm, 1149.1)   \n",
       "25          (focused, 1113.55)        (scholarly, 1146.24)   \n",
       "26          (literal, 1107.63)        (technical, 1137.57)   \n",
       "27             (bold, 1107.02)          (focused, 1136.55)   \n",
       "28        (practical, 1103.28)     (enthusiastic, 1132.11)   \n",
       "29     (unapologetic, 1102.92)          (nuanced, 1131.01)   \n",
       "30      (traditional, 1101.14)            (blunt, 1127.66)   \n",
       "31         (holistic, 1099.47)  (straightforward, 1124.84)   \n",
       "32        (universal, 1098.93)       (reflective, 1122.36)   \n",
       "33          (patient, 1096.28)        (excitable, 1116.13)   \n",
       "34        (agreeable, 1089.53)       (minimalist, 1110.15)   \n",
       "35         (tactical, 1088.91)           (direct, 1104.86)   \n",
       "36      (cooperative, 1085.15)       (colloquial, 1104.01)   \n",
       "37     (contemporary, 1083.87)           (formal, 1103.61)   \n",
       "38  (straightforward, 1077.73)      (encouraging, 1100.84)   \n",
       "39         (empirical, 1072.2)          (serious, 1098.56)   \n",
       "40     (intellectual, 1071.02)       (supportive, 1097.83)   \n",
       "41       (simplistic, 1067.12)         (assertive, 1095.8)   \n",
       "42          (nuanced, 1063.99)         (grounding, 1084.2)   \n",
       "43      (declarative, 1063.28)          (concise, 1066.36)   \n",
       "44           (serious, 1062.2)    (collaborative, 1064.76)   \n",
       "45       (innovative, 1062.08)         (tactical, 1062.51)   \n",
       "46           (casual, 1061.77)         (arrogant, 1061.08)   \n",
       "47          (factual, 1059.53)          (playful, 1060.05)   \n",
       "48         (excitable, 1057.3)       (optimistic, 1056.58)   \n",
       "49    (authoritative, 1056.99)           (casual, 1052.93)   \n",
       "\n",
       "                 trinity-mini  \n",
       "0          (precise, 1364.36)  \n",
       "1         (concrete, 1352.63)  \n",
       "2       (structured, 1348.41)  \n",
       "3       (methodical, 1296.35)  \n",
       "4       (systematic, 1279.38)  \n",
       "5        (pragmatic, 1277.61)  \n",
       "6   (straightforward, 1272.7)  \n",
       "7          (literal, 1268.44)  \n",
       "8        (objective, 1267.87)  \n",
       "9          (focused, 1250.06)  \n",
       "10         (factual, 1248.05)  \n",
       "11       (empirical, 1225.57)  \n",
       "12     (declarative, 1218.51)  \n",
       "13        (rational, 1214.59)  \n",
       "14      (analytical, 1211.15)  \n",
       "15     (specialized, 1208.17)  \n",
       "16       (grounding, 1207.97)  \n",
       "17          (formal, 1204.17)  \n",
       "18         (serious, 1202.53)  \n",
       "19     (disciplined, 1202.33)  \n",
       "20         (prosaic, 1186.41)  \n",
       "21       (elaborate, 1178.65)  \n",
       "22       (technical, 1171.16)  \n",
       "23      (respectful, 1168.18)  \n",
       "24         (logical, 1163.26)  \n",
       "25     (traditional, 1152.63)  \n",
       "26       (practical, 1152.17)  \n",
       "27      (simplistic, 1147.65)  \n",
       "28          (direct, 1147.24)  \n",
       "29     (cooperative, 1146.87)  \n",
       "30        (balanced, 1146.58)  \n",
       "31       (confident, 1136.48)  \n",
       "32        (detached, 1135.93)  \n",
       "33   (collaborative, 1127.07)  \n",
       "34       (minimalist, 1121.1)  \n",
       "35            (calm, 1118.94)  \n",
       "36        (tactical, 1116.95)  \n",
       "37        (academic, 1116.28)  \n",
       "38    (intellectual, 1114.01)  \n",
       "39    (contemporary, 1113.38)  \n",
       "40         (concise, 1112.31)  \n",
       "41       (universal, 1110.89)  \n",
       "42           (stoic, 1110.86)  \n",
       "43       (adaptable, 1106.28)  \n",
       "44   (authoritative, 1085.95)  \n",
       "45     (conservative, 1085.8)  \n",
       "46            (wise, 1077.85)  \n",
       "47       (scholarly, 1076.85)  \n",
       "48        (reserved, 1076.83)  \n",
       "49      (determined, 1073.44)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 50 traits for all models\n",
    "# Pad shorter lists so they can be displayed in a DataFrame\n",
    "max_len = max(len(v) for v in results.values())\n",
    "results_padded = {k: v + [None] * (max_len - len(v)) for k, v in results.items()}\n",
    "results_df = pd.DataFrame(results_padded)\n",
    "results_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ad5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Ranked Correlations Between All Models:\n",
      "============================================================\n",
      "claude-haiku-4.5                         vs deepseek-v3.2                           : ρ =  0.8612 (p = 1.4029e-43)\n",
      "claude-haiku-4.5                         vs gemini-3-flash-preview                  : ρ =  0.7514 (p = 2.0483e-27)\n",
      "claude-haiku-4.5                         vs gemma-3-4b-it                           : ρ =  0.1236 (p = 1.7514e-01)\n",
      "claude-haiku-4.5                         vs gpt-5.1                                 : ρ =  0.9172 (p = 1.3174e-58)\n",
      "claude-haiku-4.5                         vs grok-4.1-fast                           : ρ =  0.8010 (p = 1.9261e-33)\n",
      "claude-haiku-4.5                         vs kimi-k2-thinking                        : ρ =  0.8661 (p = 1.3579e-44)\n",
      "claude-haiku-4.5                         vs llama-3.1-8b                            : ρ =  0.7184 (p = 3.8021e-24)\n",
      "claude-haiku-4.5                         vs ministral-14b-2512                      : ρ =  0.6982 (p = 2.3496e-22)\n",
      "claude-haiku-4.5                         vs qwen3-vl-235b-a22b-thinking             : ρ =  0.7163 (p = 5.9424e-24)\n",
      "claude-haiku-4.5                         vs trinity-mini                            : ρ =  0.8292 (p = 1.0729e-37)\n",
      "deepseek-v3.2                            vs gemini-3-flash-preview                  : ρ =  0.7099 (p = 2.2701e-23)\n",
      "deepseek-v3.2                            vs gemma-3-4b-it                           : ρ =  0.1704 (p = 6.0595e-02)\n",
      "deepseek-v3.2                            vs gpt-5.1                                 : ρ =  0.8618 (p = 1.0922e-43)\n",
      "deepseek-v3.2                            vs grok-4.1-fast                           : ρ =  0.7707 (p = 1.3987e-29)\n",
      "deepseek-v3.2                            vs kimi-k2-thinking                        : ρ =  0.8599 (p = 2.6542e-43)\n",
      "deepseek-v3.2                            vs llama-3.1-8b                            : ρ =  0.7234 (p = 1.3237e-24)\n",
      "deepseek-v3.2                            vs ministral-14b-2512                      : ρ =  0.7400 (p = 3.1582e-26)\n",
      "deepseek-v3.2                            vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6682 (p = 5.7540e-20)\n",
      "deepseek-v3.2                            vs trinity-mini                            : ρ =  0.8604 (p = 2.0328e-43)\n",
      "gemini-3-flash-preview                   vs gemma-3-4b-it                           : ρ = -0.0042 (p = 9.6367e-01)\n",
      "gemini-3-flash-preview                   vs gpt-5.1                                 : ρ =  0.7287 (p = 4.1125e-25)\n",
      "gemini-3-flash-preview                   vs grok-4.1-fast                           : ρ =  0.7114 (p = 1.6580e-23)\n",
      "gemini-3-flash-preview                   vs kimi-k2-thinking                        : ρ =  0.7585 (p = 3.3969e-28)\n",
      "gemini-3-flash-preview                   vs llama-3.1-8b                            : ρ =  0.5708 (p = 8.0544e-14)\n",
      "gemini-3-flash-preview                   vs ministral-14b-2512                      : ρ =  0.6475 (p = 1.7752e-18)\n",
      "gemini-3-flash-preview                   vs qwen3-vl-235b-a22b-thinking             : ρ =  0.8120 (p = 5.1292e-35)\n",
      "gemini-3-flash-preview                   vs trinity-mini                            : ρ =  0.6874 (p = 1.8151e-21)\n",
      "gemma-3-4b-it                            vs gpt-5.1                                 : ρ =  0.1376 (p = 1.3070e-01)\n",
      "gemma-3-4b-it                            vs grok-4.1-fast                           : ρ =  0.0645 (p = 4.8048e-01)\n",
      "gemma-3-4b-it                            vs kimi-k2-thinking                        : ρ =  0.1093 (p = 2.3063e-01)\n",
      "gemma-3-4b-it                            vs llama-3.1-8b                            : ρ =  0.0746 (p = 4.1406e-01)\n",
      "gemma-3-4b-it                            vs ministral-14b-2512                      : ρ =  0.0913 (p = 3.1721e-01)\n",
      "gemma-3-4b-it                            vs qwen3-vl-235b-a22b-thinking             : ρ =  0.0763 (p = 4.0340e-01)\n",
      "gemma-3-4b-it                            vs trinity-mini                            : ρ =  0.1124 (p = 2.1768e-01)\n",
      "gpt-5.1                                  vs grok-4.1-fast                           : ρ =  0.8081 (p = 1.8913e-34)\n",
      "gpt-5.1                                  vs kimi-k2-thinking                        : ρ =  0.8988 (p = 9.9854e-53)\n",
      "gpt-5.1                                  vs llama-3.1-8b                            : ρ =  0.6525 (p = 7.9859e-19)\n",
      "gpt-5.1                                  vs ministral-14b-2512                      : ρ =  0.7037 (p = 7.8769e-23)\n",
      "gpt-5.1                                  vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6446 (p = 2.8176e-18)\n",
      "gpt-5.1                                  vs trinity-mini                            : ρ =  0.8772 (p = 4.2423e-47)\n",
      "grok-4.1-fast                            vs kimi-k2-thinking                        : ρ =  0.8123 (p = 4.5543e-35)\n",
      "grok-4.1-fast                            vs llama-3.1-8b                            : ρ =  0.5985 (p = 2.3294e-15)\n",
      "grok-4.1-fast                            vs ministral-14b-2512                      : ρ =  0.7679 (p = 2.9864e-29)\n",
      "grok-4.1-fast                            vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6779 (p = 1.0341e-20)\n",
      "grok-4.1-fast                            vs trinity-mini                            : ρ =  0.8372 (p = 4.7339e-39)\n",
      "kimi-k2-thinking                         vs llama-3.1-8b                            : ρ =  0.6055 (p = 9.0241e-16)\n",
      "kimi-k2-thinking                         vs ministral-14b-2512                      : ρ =  0.7045 (p = 6.6820e-23)\n",
      "kimi-k2-thinking                         vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6749 (p = 1.7812e-20)\n",
      "kimi-k2-thinking                         vs trinity-mini                            : ρ =  0.8543 (p = 3.4630e-42)\n",
      "llama-3.1-8b                             vs ministral-14b-2512                      : ρ =  0.7094 (p = 2.5073e-23)\n",
      "llama-3.1-8b                             vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6256 (p = 5.1358e-17)\n",
      "llama-3.1-8b                             vs trinity-mini                            : ρ =  0.6892 (p = 1.3027e-21)\n",
      "ministral-14b-2512                       vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6469 (p = 1.9836e-18)\n",
      "ministral-14b-2512                       vs trinity-mini                            : ρ =  0.7335 (p = 1.4103e-25)\n",
      "qwen3-vl-235b-a22b-thinking              vs trinity-mini                            : ρ =  0.6221 (p = 8.6252e-17)\n",
      "============================================================\n",
      "Average Correlation: ρ = 0.6249\n",
      "Min Correlation:     ρ = -0.0042\n",
      "Max Correlation:     ρ = 0.9172\n"
     ]
    }
   ],
   "source": [
    "# Calculate pairwise Spearman ranked correlations between all models\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import combinations\n",
    "\n",
    "print(\"Spearman Ranked Correlations Between All Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate all unique pairs of models\n",
    "model_pairs = list(combinations(model_names, 2))\n",
    "correlations = []\n",
    "\n",
    "for model1, model2 in model_pairs:\n",
    "    # Extract rankings (trait names in order)\n",
    "    model1_traits = [trait for trait, score in results[model1]]\n",
    "    model2_traits = [trait for trait, score in results[model2]]\n",
    "    \n",
    "    # Create rank mappings\n",
    "    model1_ranks = {trait: rank for rank, trait in enumerate(model1_traits)}\n",
    "    model2_ranks = {trait: rank for rank, trait in enumerate(model2_traits)}\n",
    "    \n",
    "    # Get common traits and their ranks\n",
    "    common_traits = set(model1_ranks.keys()) & set(model2_ranks.keys())\n",
    "    model1_rank_values = [model1_ranks[trait] for trait in common_traits]\n",
    "    model2_rank_values = [model2_ranks[trait] for trait in common_traits]\n",
    "    \n",
    "    # Calculate Spearman correlation\n",
    "    if len(common_traits) > 0:\n",
    "        correlation, p_value = spearmanr(model1_rank_values, model2_rank_values)\n",
    "        correlations.append(correlation)\n",
    "        print(f\"{model1:40s} vs {model2:40s}: ρ = {correlation:7.4f} (p = {p_value:.4e})\")\n",
    "    else:\n",
    "        print(f\"{model1:40s} vs {model2:40s}: No common traits\")\n",
    "\n",
    "if correlations:\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Average Correlation: ρ = {sum(correlations) / len(correlations):.4f}\")\n",
    "    print(f\"Min Correlation:     ρ = {min(correlations):.4f}\")\n",
    "    print(f\"Max Correlation:     ρ = {max(correlations):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b7df1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved plot to ./results/elo_distributions.png\n"
     ]
    }
   ],
   "source": [
    "# Create distribution plots for ALL 9 tested models\n",
    "# Arrange in 3 rows of 3 models each\n",
    "models_to_plot = [m for m in tested_models if m in model_names]\n",
    "\n",
    "if len(models_to_plot) > 0:\n",
    "    # Calculate grid dimensions (3 columns, enough rows)\n",
    "    n_cols = 3\n",
    "    n_rows = (len(models_to_plot) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows), sharey=True)\n",
    "    \n",
    "    # Flatten axes array for easier indexing\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Determine global x-axis limits\n",
    "    all_scores = []\n",
    "    for model in models_to_plot:\n",
    "        all_scores.extend([score for trait, score in results[model]])\n",
    "    x_min, x_max = min(all_scores)-100, max(all_scores)+100\n",
    "    \n",
    "    # Plot each model\n",
    "    for i, model in enumerate(models_to_plot):\n",
    "        ax = axes_flat[i]\n",
    "        \n",
    "        # Extract scores\n",
    "        scores = [score for trait, score in results[model]]\n",
    "        \n",
    "        # Plot histogram with density\n",
    "        ax.hist(scores, bins=20, alpha=0.7, color='steelblue', edgecolor='black', density=True)\n",
    "        \n",
    "        # Use display name if available, otherwise format the model name\n",
    "        model_label = display_names.get(model, model.replace('-', ' ').title())\n",
    "        ax.set_title(model_label, fontsize=16)\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.tick_params(axis='both', labelsize=14, width=1.2, colors='black')\n",
    "        \n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Remove top and right spines\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        # Make remaining spines thicker and darker\n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        ax.spines['left'].set_linewidth(1.5)\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        ax.spines['left'].set_color('black')\n",
    "    \n",
    "    # Hide empty subplots if we have fewer models than grid spaces\n",
    "    for i in range(len(models_to_plot), len(axes_flat)):\n",
    "        axes_flat[i].set_visible(False)\n",
    "    \n",
    "    # Set y-label on leftmost subplots of each row\n",
    "    for row in range(n_rows):\n",
    "        axes[row, 0].set_ylabel('Density', fontsize=14, weight='bold')\n",
    "    \n",
    "    # Set a single x-axis label centered across all subplots\n",
    "    fig.text(0.5, 0.02, 'Character Trait Elo Score', ha='center', fontsize=16, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.12)\n",
    "    # Save figure to file\n",
    "    import os\n",
    "    os.makedirs('./results', exist_ok=True)\n",
    "    plt.savefig('./results/elo_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved plot to ./results/elo_distributions.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"No models to plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
