{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0b9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_from_disk\n",
    "from constants import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2badbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tested models (these will be loaded from data/)\n",
    "# NOTE: This list is for reference and plotting order only\n",
    "# Only models with both .pkl files and dataset directories will actually load\n",
    "tested_models = [\n",
    "    \"claude-haiku-4.5\",\n",
    "    \"deepseek-v3.2\",\n",
    "    \"gemini-3-flash-preview\",\n",
    "    \"gpt-5.1\",\n",
    "    \"grok-4.1-fast\",\n",
    "    \"kimi-k2-thinking\",\n",
    "    \"ministral-14b-2512\",\n",
    "    \"qwen3-vl-235b-a22b-thinking\",\n",
    "    \"trinity-mini\",\n",
    "    \"gemma-3-4b-it\"\n",
    "]\n",
    "\n",
    "# Display names for plots (optional - can be customized)\n",
    "display_names = {\n",
    "    \"claude-haiku-4.5\": \"Claude Haiku 4.5\",\n",
    "    \"deepseek-v3.2\": \"DeepSeek V3.2\",\n",
    "    \"gemini-3-flash-preview\": \"Gemini 3 Flash\",\n",
    "    \"gpt-5.1\": \"GPT-5.1\",\n",
    "    \"grok-4.1-fast\": \"Grok 4.1 Fast\",\n",
    "    \"kimi-k2-thinking\": \"Kimi K2 Thinking\",\n",
    "    \"ministral-14b-2512\": \"Ministral 14B\",\n",
    "    \"qwen3-vl-235b-a22b-thinking\": \"Qwen3 VL 235B\",\n",
    "    \"trinity-mini\": \"Trinity Mini\",\n",
    "    \"gemma-3-4b-it\": \"Gemma 3 4b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b52315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elo_ratings(preferences, model_name, normalize=False):\n",
    "    # get all unique traits from the comparisons\n",
    "    traits = set()\n",
    "    for x, y, _ in preferences[model_name]:\n",
    "        traits.add(x)\n",
    "        traits.add(y)\n",
    "\n",
    "    # initialize elo ratings (starting at 1000)\n",
    "    elo_ratings = {trait: 1000.0 for trait in traits}\n",
    "    \n",
    "    # TODO: update k-factor for elo calculation\n",
    "    # TODO: Adapt k to lower value in the trait:babble case\n",
    "    K = 32\n",
    "\n",
    "    # calculate elo ratings based on comparison results\n",
    "    for trait1, trait2, winner in preferences[model_name]:\n",
    "        # get current ratings\n",
    "        r1 = elo_ratings[trait1]\n",
    "        r2 = elo_ratings[trait2]\n",
    "        \n",
    "        # calculate expected scores\n",
    "        e1 = 1 / (1 + 10**((r2 - r1) / 400))\n",
    "        e2 = 1 / (1 + 10**((r1 - r2) / 400))\n",
    "        \n",
    "        # update ratings based on actual outcome\n",
    "        if winner == trait1:\n",
    "            elo_ratings[trait1] += K * (1 - e1)\n",
    "            elo_ratings[trait2] += K * (0 - e2)\n",
    "        elif winner == trait2:\n",
    "            elo_ratings[trait1] += K * (0 - e1)\n",
    "            elo_ratings[trait2] += K * (1 - e2)\n",
    "        else:\n",
    "            # no clear winner, judge rambled\n",
    "            pass\n",
    "\n",
    "    # normalize ratings to 0-1 range if requested\n",
    "    if normalize:\n",
    "        min_rating = min(elo_ratings.values())\n",
    "        max_rating = max(elo_ratings.values())\n",
    "        rating_range = max_rating - min_rating\n",
    "        if rating_range > 0:\n",
    "            for trait in elo_ratings:\n",
    "                elo_ratings[trait] = (elo_ratings[trait] - min_rating) / rating_range\n",
    "\n",
    "    # sort ratings in descending order\n",
    "    for k, v in elo_ratings.items():\n",
    "        elo_ratings[k] = round(v, 2)\n",
    "    sorted_ratings = sorted(elo_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536338ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No dataset directory found for ministral-14b-2512, skipping...\n",
      "Warning: No dataset directory found for trinity-mini, skipping...\n",
      "Warning: No dataset directory found for deepseek-v3.2, skipping...\n",
      "✓ Loaded gemini-3-flash-preview: 10243 valid comparisons\n",
      "✓ Loaded qwen3-vl-235b-a22b-thinking: 10255 valid comparisons\n",
      "Warning: No dataset directory found for kimi-k2-thinking, skipping...\n",
      "✓ Loaded gpt-5.1: 10246 valid comparisons\n",
      "✓ Loaded claude-haiku-4.5: 10247 valid comparisons\n",
      "✓ Loaded grok-4.1-fast: 10235 valid comparisons\n",
      "\n",
      "============================================================\n",
      "Successfully loaded 5 models\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load preferences from pkl files (judge results)\n",
    "# Filter out empty responses (\"\") where judge failed to determine winner\n",
    "# Clean structure: pkl files and dataset directories are side-by-side in data/preferences/\n",
    "preferences_path = f\"{DATA_PATH}/preferences\"\n",
    "\n",
    "files = [f for f in os.listdir(preferences_path) if f.endswith(\".pkl\")]\n",
    "preferences = {}\n",
    "\n",
    "for file in files:\n",
    "    name = file.split(\".pkl\")[0]\n",
    "    pkl_path = f\"{preferences_path}/{file}\"\n",
    "    dataset_path = f\"{preferences_path}/{name}\"\n",
    "    \n",
    "    # Check if matching dataset directory exists\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        print(f\"Warning: No dataset directory found for {name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            data = load_from_disk(dataset_path)\n",
    "            winners = pickle.load(f)\n",
    "            # Filter out empty judge responses and cases where winner is not one of the traits\n",
    "            preferences[name] = [(t1, t2, winner) for t1, t2, winner in zip(data[\"trait_1\"], data[\"trait_2\"], winners) \n",
    "                                if winner and winner != \"\" and winner in [t1, t2]]\n",
    "        print(f\"✓ Loaded {name}: {len(preferences[name])} valid comparisons\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {name}: {e}\")\n",
    "\n",
    "# Get list of models from loaded data\n",
    "model_names = sorted(preferences.keys())\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Successfully loaded {len(model_names)} models\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Calculate Elo ratings for all models\n",
    "results = pd.DataFrame()\n",
    "for model in model_names:\n",
    "    sorted_ratings = calculate_elo_ratings(preferences, model, False)\n",
    "    results[model] = sorted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c729f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Models (5):\n",
      "================================================================================\n",
      "claude-haiku-4.5                              - 10247 valid trait comparisons\n",
      "gemini-3-flash-preview                        - 10243 valid trait comparisons\n",
      "gpt-5.1                                       - 10246 valid trait comparisons\n",
      "grok-4.1-fast                                 - 10235 valid trait comparisons\n",
      "qwen3-vl-235b-a22b-thinking                   - 10255 valid trait comparisons\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show summary of loaded models and their valid comparisons\n",
    "print(f\"\\nLoaded Models ({len(model_names)}):\")\n",
    "print(\"=\" * 80)\n",
    "for model in model_names:\n",
    "    valid_comparisons = len(preferences[model])\n",
    "    print(f\"{model:45s} - {valid_comparisons:5d} valid trait comparisons\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef670878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claude-haiku-4.5</th>\n",
       "      <th>gemini-3-flash-preview</th>\n",
       "      <th>gpt-5.1</th>\n",
       "      <th>grok-4.1-fast</th>\n",
       "      <th>qwen3-vl-235b-a22b-thinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(concrete, 1420.41)</td>\n",
       "      <td>(structured, 1556.26)</td>\n",
       "      <td>(structured, 1494.34)</td>\n",
       "      <td>(structured, 1445.34)</td>\n",
       "      <td>(structured, 1335.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(structured, 1408.72)</td>\n",
       "      <td>(systematic, 1520.18)</td>\n",
       "      <td>(disciplined, 1445.78)</td>\n",
       "      <td>(concrete, 1379.46)</td>\n",
       "      <td>(precise, 1334.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(grounding, 1378.89)</td>\n",
       "      <td>(scholarly, 1504.46)</td>\n",
       "      <td>(methodical, 1436.45)</td>\n",
       "      <td>(precise, 1379.39)</td>\n",
       "      <td>(methodical, 1308.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(precise, 1373.07)</td>\n",
       "      <td>(methodical, 1474.65)</td>\n",
       "      <td>(concrete, 1408.74)</td>\n",
       "      <td>(analytical, 1362.23)</td>\n",
       "      <td>(intellectual, 1291.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(practical, 1371.09)</td>\n",
       "      <td>(analytical, 1473.21)</td>\n",
       "      <td>(objective, 1382.89)</td>\n",
       "      <td>(systematic, 1341.29)</td>\n",
       "      <td>(concrete, 1279.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(methodical, 1334.38)</td>\n",
       "      <td>(logical, 1417.45)</td>\n",
       "      <td>(precise, 1367.73)</td>\n",
       "      <td>(methodical, 1332.54)</td>\n",
       "      <td>(academic, 1259.69)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(rational, 1332.24)</td>\n",
       "      <td>(academic, 1408.79)</td>\n",
       "      <td>(analytical, 1344.74)</td>\n",
       "      <td>(specialized, 1309.67)</td>\n",
       "      <td>(analytical, 1257.94)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(systematic, 1325.0)</td>\n",
       "      <td>(technical, 1400.67)</td>\n",
       "      <td>(intellectual, 1340.71)</td>\n",
       "      <td>(focused, 1298.38)</td>\n",
       "      <td>(factual, 1247.35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(cooperative, 1310.57)</td>\n",
       "      <td>(elaborate, 1395.0)</td>\n",
       "      <td>(factual, 1335.57)</td>\n",
       "      <td>(intellectual, 1294.83)</td>\n",
       "      <td>(systematic, 1246.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(balanced, 1305.31)</td>\n",
       "      <td>(intellectual, 1374.76)</td>\n",
       "      <td>(systematic, 1331.94)</td>\n",
       "      <td>(elaborate, 1283.94)</td>\n",
       "      <td>(specialized, 1239.08)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(disciplined, 1296.55)</td>\n",
       "      <td>(precise, 1372.92)</td>\n",
       "      <td>(realistic, 1315.13)</td>\n",
       "      <td>(factual, 1271.52)</td>\n",
       "      <td>(disciplined, 1230.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(intellectual, 1291.66)</td>\n",
       "      <td>(wise, 1354.94)</td>\n",
       "      <td>(elaborate, 1314.55)</td>\n",
       "      <td>(direct, 1263.04)</td>\n",
       "      <td>(authoritative, 1229.29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(analytical, 1287.28)</td>\n",
       "      <td>(nuanced, 1338.77)</td>\n",
       "      <td>(practical, 1311.35)</td>\n",
       "      <td>(objective, 1262.16)</td>\n",
       "      <td>(objective, 1223.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(elaborate, 1286.91)</td>\n",
       "      <td>(pragmatic, 1333.01)</td>\n",
       "      <td>(rational, 1310.85)</td>\n",
       "      <td>(scholarly, 1258.11)</td>\n",
       "      <td>(realistic, 1211.61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(declarative, 1259.92)</td>\n",
       "      <td>(practical, 1322.37)</td>\n",
       "      <td>(straightforward, 1303.62)</td>\n",
       "      <td>(logical, 1253.98)</td>\n",
       "      <td>(confident, 1202.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(logical, 1258.79)</td>\n",
       "      <td>(formal, 1320.13)</td>\n",
       "      <td>(perfectionist, 1296.14)</td>\n",
       "      <td>(technical, 1242.39)</td>\n",
       "      <td>(poetic, 1194.68)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(reflective, 1251.58)</td>\n",
       "      <td>(strategic, 1298.75)</td>\n",
       "      <td>(specialized, 1287.31)</td>\n",
       "      <td>(pragmatic, 1239.18)</td>\n",
       "      <td>(elaborate, 1194.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(pragmatic, 1244.39)</td>\n",
       "      <td>(objective, 1297.73)</td>\n",
       "      <td>(logical, 1286.9)</td>\n",
       "      <td>(concise, 1233.01)</td>\n",
       "      <td>(rational, 1189.54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(nuanced, 1244.37)</td>\n",
       "      <td>(tactical, 1272.87)</td>\n",
       "      <td>(wise, 1275.85)</td>\n",
       "      <td>(colloquial, 1229.8)</td>\n",
       "      <td>(practical, 1188.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(academic, 1242.66)</td>\n",
       "      <td>(contemplative, 1270.35)</td>\n",
       "      <td>(learning, 1270.12)</td>\n",
       "      <td>(balanced, 1229.38)</td>\n",
       "      <td>(pragmatic, 1187.33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(straightforward, 1235.25)</td>\n",
       "      <td>(factual, 1265.06)</td>\n",
       "      <td>(formal, 1262.08)</td>\n",
       "      <td>(disciplined, 1227.81)</td>\n",
       "      <td>(declarative, 1185.16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(focused, 1223.93)</td>\n",
       "      <td>(pedantic, 1255.78)</td>\n",
       "      <td>(balanced, 1261.02)</td>\n",
       "      <td>(practical, 1225.62)</td>\n",
       "      <td>(logical, 1172.31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(factual, 1220.74)</td>\n",
       "      <td>(disciplined, 1254.4)</td>\n",
       "      <td>(pragmatic, 1246.29)</td>\n",
       "      <td>(empirical, 1216.91)</td>\n",
       "      <td>(cooperative, 1163.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(wise, 1216.26)</td>\n",
       "      <td>(collaborative, 1254.07)</td>\n",
       "      <td>(technical, 1243.14)</td>\n",
       "      <td>(straightforward, 1208.48)</td>\n",
       "      <td>(empirical, 1155.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(realistic, 1214.99)</td>\n",
       "      <td>(specialized, 1253.86)</td>\n",
       "      <td>(academic, 1240.64)</td>\n",
       "      <td>(rational, 1190.13)</td>\n",
       "      <td>(warm, 1149.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(objective, 1208.8)</td>\n",
       "      <td>(rational, 1245.85)</td>\n",
       "      <td>(cooperative, 1235.24)</td>\n",
       "      <td>(enthusiastic, 1189.38)</td>\n",
       "      <td>(scholarly, 1146.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(holistic, 1205.22)</td>\n",
       "      <td>(straightforward, 1240.32)</td>\n",
       "      <td>(grounding, 1233.17)</td>\n",
       "      <td>(realistic, 1186.87)</td>\n",
       "      <td>(technical, 1137.57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(specialized, 1203.92)</td>\n",
       "      <td>(focused, 1239.05)</td>\n",
       "      <td>(authoritative, 1233.12)</td>\n",
       "      <td>(strategic, 1175.66)</td>\n",
       "      <td>(focused, 1136.55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(literal, 1195.05)</td>\n",
       "      <td>(concrete, 1223.74)</td>\n",
       "      <td>(focused, 1229.59)</td>\n",
       "      <td>(confident, 1172.26)</td>\n",
       "      <td>(enthusiastic, 1132.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(contemplative, 1184.07)</td>\n",
       "      <td>(cooperative, 1213.67)</td>\n",
       "      <td>(patient, 1226.38)</td>\n",
       "      <td>(wise, 1171.34)</td>\n",
       "      <td>(nuanced, 1131.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(learning, 1180.11)</td>\n",
       "      <td>(philosophical, 1203.98)</td>\n",
       "      <td>(confident, 1220.77)</td>\n",
       "      <td>(grounding, 1164.52)</td>\n",
       "      <td>(blunt, 1127.66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(supportive, 1177.27)</td>\n",
       "      <td>(calm, 1201.18)</td>\n",
       "      <td>(declarative, 1220.57)</td>\n",
       "      <td>(casual, 1164.17)</td>\n",
       "      <td>(straightforward, 1124.84)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(prosaic, 1169.34)</td>\n",
       "      <td>(confident, 1196.39)</td>\n",
       "      <td>(calm, 1219.55)</td>\n",
       "      <td>(academic, 1163.25)</td>\n",
       "      <td>(reflective, 1122.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(confident, 1166.71)</td>\n",
       "      <td>(creative, 1195.0)</td>\n",
       "      <td>(strategic, 1215.52)</td>\n",
       "      <td>(declarative, 1144.29)</td>\n",
       "      <td>(excitable, 1116.13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(collaborative, 1166.62)</td>\n",
       "      <td>(reflective, 1194.41)</td>\n",
       "      <td>(respectful, 1208.3)</td>\n",
       "      <td>(traditional, 1138.57)</td>\n",
       "      <td>(minimalist, 1110.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(empirical, 1164.21)</td>\n",
       "      <td>(verbose, 1184.35)</td>\n",
       "      <td>(prosaic, 1193.7)</td>\n",
       "      <td>(playful, 1138.55)</td>\n",
       "      <td>(direct, 1104.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(serious, 1160.35)</td>\n",
       "      <td>(decisive, 1175.81)</td>\n",
       "      <td>(universal, 1187.93)</td>\n",
       "      <td>(organic, 1138.43)</td>\n",
       "      <td>(colloquial, 1104.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(technical, 1154.48)</td>\n",
       "      <td>(visionary, 1173.48)</td>\n",
       "      <td>(holistic, 1178.21)</td>\n",
       "      <td>(serious, 1137.77)</td>\n",
       "      <td>(formal, 1103.61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(formal, 1135.93)</td>\n",
       "      <td>(supportive, 1167.96)</td>\n",
       "      <td>(scholarly, 1178.14)</td>\n",
       "      <td>(respectful, 1133.35)</td>\n",
       "      <td>(encouraging, 1100.84)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(detached, 1130.77)</td>\n",
       "      <td>(literal, 1161.27)</td>\n",
       "      <td>(serious, 1177.44)</td>\n",
       "      <td>(cool, 1132.97)</td>\n",
       "      <td>(serious, 1098.56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(calm, 1124.19)</td>\n",
       "      <td>(poetic, 1160.91)</td>\n",
       "      <td>(adaptable, 1174.29)</td>\n",
       "      <td>(bold, 1132.73)</td>\n",
       "      <td>(supportive, 1097.83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(contemporary, 1120.72)</td>\n",
       "      <td>(encouraging, 1148.48)</td>\n",
       "      <td>(verbose, 1172.99)</td>\n",
       "      <td>(tactical, 1132.13)</td>\n",
       "      <td>(assertive, 1095.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(stoic, 1116.68)</td>\n",
       "      <td>(concise, 1141.42)</td>\n",
       "      <td>(tactical, 1169.74)</td>\n",
       "      <td>(collaborative, 1131.16)</td>\n",
       "      <td>(grounding, 1084.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(flexible, 1113.31)</td>\n",
       "      <td>(perfectionist, 1139.27)</td>\n",
       "      <td>(literal, 1163.08)</td>\n",
       "      <td>(humorous, 1128.46)</td>\n",
       "      <td>(concise, 1066.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(patient, 1112.99)</td>\n",
       "      <td>(direct, 1136.78)</td>\n",
       "      <td>(empirical, 1154.59)</td>\n",
       "      <td>(cooperative, 1119.66)</td>\n",
       "      <td>(collaborative, 1064.76)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(authoritative, 1110.32)</td>\n",
       "      <td>(empirical, 1133.75)</td>\n",
       "      <td>(cautious, 1146.63)</td>\n",
       "      <td>(formal, 1118.64)</td>\n",
       "      <td>(tactical, 1062.51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(colloquial, 1108.84)</td>\n",
       "      <td>(balanced, 1128.98)</td>\n",
       "      <td>(nuanced, 1136.75)</td>\n",
       "      <td>(contemporary, 1118.35)</td>\n",
       "      <td>(arrogant, 1061.08)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(strategic, 1105.52)</td>\n",
       "      <td>(declarative, 1128.88)</td>\n",
       "      <td>(gentle, 1130.03)</td>\n",
       "      <td>(optimistic, 1116.85)</td>\n",
       "      <td>(playful, 1060.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(respectful, 1104.9)</td>\n",
       "      <td>(realistic, 1126.94)</td>\n",
       "      <td>(contemporary, 1126.79)</td>\n",
       "      <td>(irreverent, 1108.77)</td>\n",
       "      <td>(optimistic, 1056.58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(traditional, 1102.55)</td>\n",
       "      <td>(serious, 1122.81)</td>\n",
       "      <td>(direct, 1123.76)</td>\n",
       "      <td>(harmonious, 1096.03)</td>\n",
       "      <td>(casual, 1052.93)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              claude-haiku-4.5      gemini-3-flash-preview  \\\n",
       "0          (concrete, 1420.41)       (structured, 1556.26)   \n",
       "1        (structured, 1408.72)       (systematic, 1520.18)   \n",
       "2         (grounding, 1378.89)        (scholarly, 1504.46)   \n",
       "3           (precise, 1373.07)       (methodical, 1474.65)   \n",
       "4         (practical, 1371.09)       (analytical, 1473.21)   \n",
       "5        (methodical, 1334.38)          (logical, 1417.45)   \n",
       "6          (rational, 1332.24)         (academic, 1408.79)   \n",
       "7         (systematic, 1325.0)        (technical, 1400.67)   \n",
       "8       (cooperative, 1310.57)         (elaborate, 1395.0)   \n",
       "9          (balanced, 1305.31)     (intellectual, 1374.76)   \n",
       "10      (disciplined, 1296.55)          (precise, 1372.92)   \n",
       "11     (intellectual, 1291.66)             (wise, 1354.94)   \n",
       "12       (analytical, 1287.28)          (nuanced, 1338.77)   \n",
       "13        (elaborate, 1286.91)        (pragmatic, 1333.01)   \n",
       "14      (declarative, 1259.92)        (practical, 1322.37)   \n",
       "15          (logical, 1258.79)           (formal, 1320.13)   \n",
       "16       (reflective, 1251.58)        (strategic, 1298.75)   \n",
       "17        (pragmatic, 1244.39)        (objective, 1297.73)   \n",
       "18          (nuanced, 1244.37)         (tactical, 1272.87)   \n",
       "19         (academic, 1242.66)    (contemplative, 1270.35)   \n",
       "20  (straightforward, 1235.25)          (factual, 1265.06)   \n",
       "21          (focused, 1223.93)         (pedantic, 1255.78)   \n",
       "22          (factual, 1220.74)       (disciplined, 1254.4)   \n",
       "23             (wise, 1216.26)    (collaborative, 1254.07)   \n",
       "24        (realistic, 1214.99)      (specialized, 1253.86)   \n",
       "25         (objective, 1208.8)         (rational, 1245.85)   \n",
       "26         (holistic, 1205.22)  (straightforward, 1240.32)   \n",
       "27      (specialized, 1203.92)          (focused, 1239.05)   \n",
       "28          (literal, 1195.05)         (concrete, 1223.74)   \n",
       "29    (contemplative, 1184.07)      (cooperative, 1213.67)   \n",
       "30         (learning, 1180.11)    (philosophical, 1203.98)   \n",
       "31       (supportive, 1177.27)             (calm, 1201.18)   \n",
       "32          (prosaic, 1169.34)        (confident, 1196.39)   \n",
       "33        (confident, 1166.71)          (creative, 1195.0)   \n",
       "34    (collaborative, 1166.62)       (reflective, 1194.41)   \n",
       "35        (empirical, 1164.21)          (verbose, 1184.35)   \n",
       "36          (serious, 1160.35)         (decisive, 1175.81)   \n",
       "37        (technical, 1154.48)        (visionary, 1173.48)   \n",
       "38           (formal, 1135.93)       (supportive, 1167.96)   \n",
       "39         (detached, 1130.77)          (literal, 1161.27)   \n",
       "40             (calm, 1124.19)           (poetic, 1160.91)   \n",
       "41     (contemporary, 1120.72)      (encouraging, 1148.48)   \n",
       "42            (stoic, 1116.68)          (concise, 1141.42)   \n",
       "43         (flexible, 1113.31)    (perfectionist, 1139.27)   \n",
       "44          (patient, 1112.99)           (direct, 1136.78)   \n",
       "45    (authoritative, 1110.32)        (empirical, 1133.75)   \n",
       "46       (colloquial, 1108.84)         (balanced, 1128.98)   \n",
       "47        (strategic, 1105.52)      (declarative, 1128.88)   \n",
       "48        (respectful, 1104.9)        (realistic, 1126.94)   \n",
       "49      (traditional, 1102.55)          (serious, 1122.81)   \n",
       "\n",
       "                       gpt-5.1               grok-4.1-fast  \\\n",
       "0        (structured, 1494.34)       (structured, 1445.34)   \n",
       "1       (disciplined, 1445.78)         (concrete, 1379.46)   \n",
       "2        (methodical, 1436.45)          (precise, 1379.39)   \n",
       "3          (concrete, 1408.74)       (analytical, 1362.23)   \n",
       "4         (objective, 1382.89)       (systematic, 1341.29)   \n",
       "5           (precise, 1367.73)       (methodical, 1332.54)   \n",
       "6        (analytical, 1344.74)      (specialized, 1309.67)   \n",
       "7      (intellectual, 1340.71)          (focused, 1298.38)   \n",
       "8           (factual, 1335.57)     (intellectual, 1294.83)   \n",
       "9        (systematic, 1331.94)        (elaborate, 1283.94)   \n",
       "10        (realistic, 1315.13)          (factual, 1271.52)   \n",
       "11        (elaborate, 1314.55)           (direct, 1263.04)   \n",
       "12        (practical, 1311.35)        (objective, 1262.16)   \n",
       "13         (rational, 1310.85)        (scholarly, 1258.11)   \n",
       "14  (straightforward, 1303.62)          (logical, 1253.98)   \n",
       "15    (perfectionist, 1296.14)        (technical, 1242.39)   \n",
       "16      (specialized, 1287.31)        (pragmatic, 1239.18)   \n",
       "17           (logical, 1286.9)          (concise, 1233.01)   \n",
       "18             (wise, 1275.85)        (colloquial, 1229.8)   \n",
       "19         (learning, 1270.12)         (balanced, 1229.38)   \n",
       "20           (formal, 1262.08)      (disciplined, 1227.81)   \n",
       "21         (balanced, 1261.02)        (practical, 1225.62)   \n",
       "22        (pragmatic, 1246.29)        (empirical, 1216.91)   \n",
       "23        (technical, 1243.14)  (straightforward, 1208.48)   \n",
       "24         (academic, 1240.64)         (rational, 1190.13)   \n",
       "25      (cooperative, 1235.24)     (enthusiastic, 1189.38)   \n",
       "26        (grounding, 1233.17)        (realistic, 1186.87)   \n",
       "27    (authoritative, 1233.12)        (strategic, 1175.66)   \n",
       "28          (focused, 1229.59)        (confident, 1172.26)   \n",
       "29          (patient, 1226.38)             (wise, 1171.34)   \n",
       "30        (confident, 1220.77)        (grounding, 1164.52)   \n",
       "31      (declarative, 1220.57)           (casual, 1164.17)   \n",
       "32             (calm, 1219.55)         (academic, 1163.25)   \n",
       "33        (strategic, 1215.52)      (declarative, 1144.29)   \n",
       "34        (respectful, 1208.3)      (traditional, 1138.57)   \n",
       "35           (prosaic, 1193.7)          (playful, 1138.55)   \n",
       "36        (universal, 1187.93)          (organic, 1138.43)   \n",
       "37         (holistic, 1178.21)          (serious, 1137.77)   \n",
       "38        (scholarly, 1178.14)       (respectful, 1133.35)   \n",
       "39          (serious, 1177.44)             (cool, 1132.97)   \n",
       "40        (adaptable, 1174.29)             (bold, 1132.73)   \n",
       "41          (verbose, 1172.99)         (tactical, 1132.13)   \n",
       "42         (tactical, 1169.74)    (collaborative, 1131.16)   \n",
       "43          (literal, 1163.08)         (humorous, 1128.46)   \n",
       "44        (empirical, 1154.59)      (cooperative, 1119.66)   \n",
       "45         (cautious, 1146.63)           (formal, 1118.64)   \n",
       "46          (nuanced, 1136.75)     (contemporary, 1118.35)   \n",
       "47           (gentle, 1130.03)       (optimistic, 1116.85)   \n",
       "48     (contemporary, 1126.79)       (irreverent, 1108.77)   \n",
       "49           (direct, 1123.76)       (harmonious, 1096.03)   \n",
       "\n",
       "   qwen3-vl-235b-a22b-thinking  \n",
       "0        (structured, 1335.22)  \n",
       "1           (precise, 1334.04)  \n",
       "2        (methodical, 1308.73)  \n",
       "3      (intellectual, 1291.15)  \n",
       "4          (concrete, 1279.02)  \n",
       "5          (academic, 1259.69)  \n",
       "6        (analytical, 1257.94)  \n",
       "7           (factual, 1247.35)  \n",
       "8         (systematic, 1246.5)  \n",
       "9       (specialized, 1239.08)  \n",
       "10      (disciplined, 1230.05)  \n",
       "11    (authoritative, 1229.29)  \n",
       "12        (objective, 1223.02)  \n",
       "13        (realistic, 1211.61)  \n",
       "14        (confident, 1202.07)  \n",
       "15           (poetic, 1194.68)  \n",
       "16         (elaborate, 1194.4)  \n",
       "17         (rational, 1189.54)  \n",
       "18        (practical, 1188.86)  \n",
       "19        (pragmatic, 1187.33)  \n",
       "20      (declarative, 1185.16)  \n",
       "21          (logical, 1172.31)  \n",
       "22       (cooperative, 1163.1)  \n",
       "23        (empirical, 1155.17)  \n",
       "24              (warm, 1149.1)  \n",
       "25        (scholarly, 1146.24)  \n",
       "26        (technical, 1137.57)  \n",
       "27          (focused, 1136.55)  \n",
       "28     (enthusiastic, 1132.11)  \n",
       "29          (nuanced, 1131.01)  \n",
       "30            (blunt, 1127.66)  \n",
       "31  (straightforward, 1124.84)  \n",
       "32       (reflective, 1122.36)  \n",
       "33        (excitable, 1116.13)  \n",
       "34       (minimalist, 1110.15)  \n",
       "35           (direct, 1104.86)  \n",
       "36       (colloquial, 1104.01)  \n",
       "37           (formal, 1103.61)  \n",
       "38      (encouraging, 1100.84)  \n",
       "39          (serious, 1098.56)  \n",
       "40       (supportive, 1097.83)  \n",
       "41         (assertive, 1095.8)  \n",
       "42         (grounding, 1084.2)  \n",
       "43          (concise, 1066.36)  \n",
       "44    (collaborative, 1064.76)  \n",
       "45         (tactical, 1062.51)  \n",
       "46         (arrogant, 1061.08)  \n",
       "47          (playful, 1060.05)  \n",
       "48       (optimistic, 1056.58)  \n",
       "49           (casual, 1052.93)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 traits for first few models\n",
    "results.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ad5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Ranked Correlations Between All Models:\n",
      "============================================================\n",
      "claude-haiku-4.5                         vs gemini-3-flash-preview                  : ρ =  0.7514 (p = 2.0483e-27)\n",
      "claude-haiku-4.5                         vs gpt-5.1                                 : ρ =  0.9172 (p = 1.3174e-58)\n",
      "claude-haiku-4.5                         vs grok-4.1-fast                           : ρ =  0.7897 (p = 6.2575e-32)\n",
      "claude-haiku-4.5                         vs qwen3-vl-235b-a22b-thinking             : ρ =  0.7163 (p = 5.9424e-24)\n",
      "gemini-3-flash-preview                   vs gpt-5.1                                 : ρ =  0.7287 (p = 4.1125e-25)\n",
      "gemini-3-flash-preview                   vs grok-4.1-fast                           : ρ =  0.7821 (p = 5.8195e-31)\n",
      "gemini-3-flash-preview                   vs qwen3-vl-235b-a22b-thinking             : ρ =  0.8120 (p = 5.1292e-35)\n",
      "gpt-5.1                                  vs grok-4.1-fast                           : ρ =  0.7625 (p = 1.2209e-28)\n",
      "gpt-5.1                                  vs qwen3-vl-235b-a22b-thinking             : ρ =  0.6446 (p = 2.8176e-18)\n",
      "grok-4.1-fast                            vs qwen3-vl-235b-a22b-thinking             : ρ =  0.7865 (p = 1.5990e-31)\n",
      "============================================================\n",
      "Average Correlation: ρ = 0.7691\n",
      "Min Correlation:     ρ = 0.6446\n",
      "Max Correlation:     ρ = 0.9172\n"
     ]
    }
   ],
   "source": [
    "# Calculate pairwise Spearman ranked correlations between all models\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import combinations\n",
    "\n",
    "print(\"Spearman Ranked Correlations Between All Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate all unique pairs of models\n",
    "model_pairs = list(combinations(model_names, 2))\n",
    "correlations = []\n",
    "\n",
    "for model1, model2 in model_pairs:\n",
    "    # Extract rankings (trait names in order)\n",
    "    model1_traits = [trait for trait, score in results[model1].tolist()]\n",
    "    model2_traits = [trait for trait, score in results[model2].tolist()]\n",
    "    \n",
    "    # Create rank mappings\n",
    "    model1_ranks = {trait: rank for rank, trait in enumerate(model1_traits)}\n",
    "    model2_ranks = {trait: rank for rank, trait in enumerate(model2_traits)}\n",
    "    \n",
    "    # Get common traits and their ranks\n",
    "    common_traits = set(model1_ranks.keys()) & set(model2_ranks.keys())\n",
    "    model1_rank_values = [model1_ranks[trait] for trait in common_traits]\n",
    "    model2_rank_values = [model2_ranks[trait] for trait in common_traits]\n",
    "    \n",
    "    # Calculate Spearman correlation\n",
    "    if len(common_traits) > 0:\n",
    "        correlation, p_value = spearmanr(model1_rank_values, model2_rank_values)\n",
    "        correlations.append(correlation)\n",
    "        print(f\"{model1:40s} vs {model2:40s}: ρ = {correlation:7.4f} (p = {p_value:.4e})\")\n",
    "    else:\n",
    "        print(f\"{model1:40s} vs {model2:40s}: No common traits\")\n",
    "\n",
    "if correlations:\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Average Correlation: ρ = {sum(correlations) / len(correlations):.4f}\")\n",
    "    print(f\"Min Correlation:     ρ = {min(correlations):.4f}\")\n",
    "    print(f\"Max Correlation:     ρ = {max(correlations):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b7df1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2730894319.py, line 70)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31melse:\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create distribution plots for ALL 9 tested models\n",
    "# Arrange in 3 rows of 3 models each\n",
    "models_to_plot = [m for m in tested_models if m in model_names]\n",
    "\n",
    "if len(models_to_plot) > 0:\n",
    "    # Calculate grid dimensions (3 columns, enough rows)\n",
    "    n_cols = 3\n",
    "    n_rows = (len(models_to_plot) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows), sharey=True)\n",
    "    \n",
    "    # Flatten axes array for easier indexing\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Determine global x-axis limits\n",
    "    all_scores = []\n",
    "    for model in models_to_plot:\n",
    "        all_scores.extend([score for trait, score in results[model].tolist()])\n",
    "    x_min, x_max = min(all_scores)-100, max(all_scores)+100\n",
    "    \n",
    "    # Plot each model\n",
    "    for i, model in enumerate(models_to_plot):\n",
    "        ax = axes_flat[i]\n",
    "        \n",
    "        # Extract scores\n",
    "        scores = [score for trait, score in results[model].tolist()]\n",
    "        \n",
    "        # Plot histogram with density\n",
    "        ax.hist(scores, bins=20, alpha=0.7, color='steelblue', edgecolor='black', density=True)\n",
    "        \n",
    "        # Use display name if available, otherwise format the model name\n",
    "        model_label = display_names.get(model, model.replace('-', ' ').title())\n",
    "        ax.set_title(model_label, fontsize=16)\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.tick_params(axis='both', labelsize=14, width=1.2, colors='black')\n",
    "        \n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Remove top and right spines\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        # Make remaining spines thicker and darker\n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        ax.spines['left'].set_linewidth(1.5)\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        ax.spines['left'].set_color('black')\n",
    "    \n",
    "    # Hide empty subplots if we have fewer models than grid spaces\n",
    "    for i in range(len(models_to_plot), len(axes_flat)):\n",
    "        axes_flat[i].set_visible(False)\n",
    "    \n",
    "    # Set y-label on leftmost subplots of each row\n",
    "    for row in range(n_rows):\n",
    "        axes[row, 0].set_ylabel('Density', fontsize=14, weight='bold')\n",
    "    \n",
    "    # Set a single x-axis label centered across all subplots\n",
    "    fig.text(0.5, 0.02, 'Character Trait Elo Score', ha='center', fontsize=16, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.12)\n",
    "    # Save figure to file\n",
    "import os\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "plt.savefig('./results/elo_distributions.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✅ Saved plot to ./results/elo_distributions.png\")\n",
    "plt.close()\n",
    "else:\n",
    "    print(\"No models to plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
