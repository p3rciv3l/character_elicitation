models:
  # OpenAI
  - name: gpt-5.1
    model: openai/gpt-5.1:floor
    top_p: 1.0
    max_tokens: 2048
    provider:
      quantizations: []
      
  - name: gpt-4o
    model: openai/gpt-4o-2024-08-06:floor
    max_tokens: 2048
    provider:
      quantizations: []

  # Anthropic
  - name: claude-haiku-4.5
    model: anthropic/claude-haiku-4.5:floor
    max_tokens: 2048
    reasoning: null
    verbosity: null
    provider:
      quantizations: []

  # xAI
  # grok is known to prefer more deterministic outcomes
  - name: grok-4.1-fast
    model: x-ai/grok-4.1-fast:floor
    temperature: 0.7
    provider:
      quantizations: []

  # Google
  - name: gemini-3-flash-preview
    model: google/gemini-3-flash-preview:floor
    provider:
      quantizations: []

  # Mistral
  - name: ministral-14b-2512
    model: mistralai/ministral-14b-2512:nitro
    provider:
      quantizations: []

  # Alibaba
  - name: qwen3-vl-235b-a22b-thinking
    model: qwen/qwen3-vl-235b-a22b-thinking:nitro
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    repetition_penalty: 1.0
    presence_penalty: 1.5

  # Moonshot
  # https://platform.moonshot.ai/docs/guide/use-kimi-k2-thinking-model#usage-notes
  - name: kimi-k2-thinking
    model: moonshotai/kimi-k2-thinking:floor

  # DeepSeek
  # https://huggingface.co/deepseek-ai/DeepSeek-V3.2
  - name: deepseek-v3.2
    model: deepseek/deepseek-v3.2:nitro
    top_p: 0.95

  # Arcee
  # https://huggingface.co/arcee-ai/Trinity-Mini-GGUF?
  - name: trinity-mini
    model: arcee-ai/trinity-mini:floor
    temperature: 0.15
    top_p: 0.75
    top_k: 50
    min_p: 0.06

  # judge models
  # Z.ai
  - name: glm-4.5-air
    model: z-ai/glm-4.5-air:floor
    temperature: 0.1
    top_p: 0.95
    max_tokens: 2048
  
  - name: trinity-mini-judge
    model: arcee-ai/trinity-mini:nitro
    temperature: 0.1
    top_p: 0.95
    max_tokens: 2048

  # free inference
  # Z-AI Free
  - name: glm-4.5-air-free
    model: z-ai/glm-4.5-air:free
    temperature: 0.15
    top_p: 0.75
    top_k: 50
    min_p: 0.06
 
# cheap but not free inference
# Llama 3.2
  - name: llama-3.2-3b
    model: meta-llama/llama-3.2-3b-instruct:nitro
